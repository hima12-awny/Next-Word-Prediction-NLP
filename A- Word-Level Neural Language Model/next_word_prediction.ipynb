{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# How to Develop a Word-Level Neural Language <br> Model and Use it to Generate Text\n",
        "\n",
        "this part/version A to get next words of seed text.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import libs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from pickle import dump, load\n",
        "\n",
        "import random\n",
        "import pprint"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5XB8w3GOyUVi"
      },
      "outputs": [],
      "source": [
        "def load_doc(path: str) -> str:\n",
        "    with open(path, 'r') as file:\n",
        "        data = file.read()\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3ISaJsXyUVm",
        "outputId": "854f3826-420c-48f8-d3c4-a77d88980757"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle\n",
            "\n",
            "This eBook is for the use of anyone anywhere at no cost and with\n",
            "almost no restrictions whatsoever.  You may copy it, giv\n"
          ]
        }
      ],
      "source": [
        "filepath = '/content/1661-0.txt'\n",
        "doc = load_doc(filepath)\n",
        "print(doc[:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYeGrp4tyUVp",
        "outputId": "1e1cf0b1-d02f-4d48-ae20-51960f8c5845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text nlp done.\n"
          ]
        }
      ],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "def clean_doc(doc: str):\n",
        "    text = nlp(doc)\n",
        "    print('text nlp done.')\n",
        "    return [i.text.lower() for i in text if i.is_alpha]\n",
        "\n",
        "\n",
        "toknize = clean_doc(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wbg2CUCVyUVr",
        "outputId": "0ef70a96-6f76-4610-eeba-c4499489fa9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokinze len 107645\n",
            "Tokinze unique len 8043\n"
          ]
        }
      ],
      "source": [
        "print(f'Tokinze len {len(toknize)}')\n",
        "print(f'Tokinze unique len {len(set(toknize))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnlJF0uQyUVs",
        "outputId": "c9372a32-d1a9-4a23-daa4-023bf472cb63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the len of sequences: 107594\n"
          ]
        }
      ],
      "source": [
        "prev_words_len = 50\n",
        "length = prev_words_len + 1\n",
        "\n",
        "sequences = list()\n",
        "\n",
        "for i in range(length, len(toknize)):\n",
        "    sequences.append(' '.join(toknize[i-length:i]))\n",
        "\n",
        "print(f'the len of sequences: {len(sequences)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8mNfj1o_yUVt"
      },
      "outputs": [],
      "source": [
        "def save_doc(lines, filename):\n",
        "    with open(filename, 'w') as file:\n",
        "        file.write('\\n'.join(lines))\n",
        "\n",
        "\n",
        "outlinesSeq = 'r1661-0_sequences.txt'\n",
        "save_doc(sequences, outlinesSeq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Z1VHNQjryUVu"
      },
      "outputs": [],
      "source": [
        "lines = load_doc('r1661-0_sequences.txt').split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Y-BZ8IhkyUVv"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oSNnct40yUVw"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PZpUH5yRyUVx"
      },
      "outputs": [],
      "source": [
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:, :-1], sequences[:, -1]\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "seq_len = X.shape[1]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define the Model And Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHocWxgiyUVy",
        "outputId": "308ad812-488b-4b80-8298-b98851f91a19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 50, 50)            402200    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 50, 100)           60400     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8044)              812444    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,365,544\n",
            "Trainable params: 1,365,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(vocab_size, prev_words_len, input_length=seq_len))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISRco0C8yUVz",
        "outputId": "0467f99c-1e5b-4355-cc41-2caec398d7a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "841/841 [==============================] - 62s 62ms/step - loss: 6.4776 - accuracy: 0.0557\n",
            "Epoch 2/100\n",
            "841/841 [==============================] - 17s 21ms/step - loss: 6.0066 - accuracy: 0.0757\n",
            "Epoch 3/100\n",
            "841/841 [==============================] - 14s 16ms/step - loss: 5.7592 - accuracy: 0.0924\n",
            "Epoch 4/100\n",
            "841/841 [==============================] - 13s 16ms/step - loss: 5.5962 - accuracy: 0.1048\n",
            "Epoch 5/100\n",
            "841/841 [==============================] - 13s 15ms/step - loss: 5.4648 - accuracy: 0.1161\n",
            "Epoch 6/100\n",
            "841/841 [==============================] - 14s 16ms/step - loss: 5.3484 - accuracy: 0.1224\n",
            "Epoch 7/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 5.2435 - accuracy: 0.1294\n",
            "Epoch 8/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 5.1474 - accuracy: 0.1347\n",
            "Epoch 9/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 5.0577 - accuracy: 0.1397\n",
            "Epoch 10/100\n",
            "841/841 [==============================] - 13s 15ms/step - loss: 4.9740 - accuracy: 0.1420\n",
            "Epoch 11/100\n",
            "841/841 [==============================] - 11s 14ms/step - loss: 4.8944 - accuracy: 0.1460\n",
            "Epoch 12/100\n",
            "841/841 [==============================] - 11s 14ms/step - loss: 4.8150 - accuracy: 0.1502\n",
            "Epoch 13/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 4.7389 - accuracy: 0.1537\n",
            "Epoch 14/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 4.6712 - accuracy: 0.1571\n",
            "Epoch 15/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 4.6031 - accuracy: 0.1602\n",
            "Epoch 16/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 4.5409 - accuracy: 0.1635\n",
            "Epoch 17/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 4.4824 - accuracy: 0.1662\n",
            "Epoch 18/100\n",
            "841/841 [==============================] - 11s 14ms/step - loss: 4.4401 - accuracy: 0.1689\n",
            "Epoch 19/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 4.3797 - accuracy: 0.1713\n",
            "Epoch 20/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 4.3300 - accuracy: 0.1747\n",
            "Epoch 21/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 4.2838 - accuracy: 0.1772\n",
            "Epoch 22/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 4.2416 - accuracy: 0.1821\n",
            "Epoch 23/100\n",
            "841/841 [==============================] - 11s 14ms/step - loss: 4.2012 - accuracy: 0.1842\n",
            "Epoch 24/100\n",
            "841/841 [==============================] - 11s 14ms/step - loss: 4.1633 - accuracy: 0.1877\n",
            "Epoch 25/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 4.1250 - accuracy: 0.1908\n",
            "Epoch 26/100\n",
            "841/841 [==============================] - 11s 14ms/step - loss: 4.0899 - accuracy: 0.1947\n",
            "Epoch 27/100\n",
            "841/841 [==============================] - 11s 14ms/step - loss: 4.0550 - accuracy: 0.1978\n",
            "Epoch 28/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 4.0230 - accuracy: 0.2013\n",
            "Epoch 29/100\n",
            "841/841 [==============================] - 11s 14ms/step - loss: 3.9924 - accuracy: 0.2043\n",
            "Epoch 30/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 3.9596 - accuracy: 0.2084\n",
            "Epoch 31/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 3.9319 - accuracy: 0.2112\n",
            "Epoch 32/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 3.9026 - accuracy: 0.2149\n",
            "Epoch 33/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 3.8745 - accuracy: 0.2177\n",
            "Epoch 34/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 3.8458 - accuracy: 0.2201\n",
            "Epoch 35/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 3.8185 - accuracy: 0.2240\n",
            "Epoch 36/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 3.7910 - accuracy: 0.2266\n",
            "Epoch 37/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 3.7644 - accuracy: 0.2304\n",
            "Epoch 38/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 3.7396 - accuracy: 0.2334\n",
            "Epoch 39/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 3.7149 - accuracy: 0.2362\n",
            "Epoch 40/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 3.6884 - accuracy: 0.2401\n",
            "Epoch 41/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 3.6644 - accuracy: 0.2429\n",
            "Epoch 42/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 3.6403 - accuracy: 0.2453\n",
            "Epoch 43/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 3.6175 - accuracy: 0.2497\n",
            "Epoch 44/100\n",
            "841/841 [==============================] - 11s 14ms/step - loss: 3.5928 - accuracy: 0.2517\n",
            "Epoch 45/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 3.5686 - accuracy: 0.2554\n",
            "Epoch 46/100\n",
            "841/841 [==============================] - 11s 14ms/step - loss: 3.5479 - accuracy: 0.2583\n",
            "Epoch 47/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 3.5245 - accuracy: 0.2615\n",
            "Epoch 48/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 3.5028 - accuracy: 0.2641\n",
            "Epoch 49/100\n",
            "841/841 [==============================] - 11s 14ms/step - loss: 3.4826 - accuracy: 0.2668\n",
            "Epoch 50/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 3.4585 - accuracy: 0.2699\n",
            "Epoch 51/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 3.4349 - accuracy: 0.2720\n",
            "Epoch 52/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 3.4171 - accuracy: 0.2755\n",
            "Epoch 53/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 3.3994 - accuracy: 0.2789\n",
            "Epoch 54/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 3.3778 - accuracy: 0.2821\n",
            "Epoch 55/100\n",
            "841/841 [==============================] - 11s 14ms/step - loss: 3.3575 - accuracy: 0.2851\n",
            "Epoch 56/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 3.3359 - accuracy: 0.2870\n",
            "Epoch 57/100\n",
            "841/841 [==============================] - 11s 14ms/step - loss: 3.3172 - accuracy: 0.2903\n",
            "Epoch 58/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 3.3000 - accuracy: 0.2921\n",
            "Epoch 59/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 3.2793 - accuracy: 0.2946\n",
            "Epoch 60/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 3.2601 - accuracy: 0.2990\n",
            "Epoch 61/100\n",
            "841/841 [==============================] - 11s 14ms/step - loss: 3.2388 - accuracy: 0.3018\n",
            "Epoch 62/100\n",
            "841/841 [==============================] - 11s 14ms/step - loss: 3.2234 - accuracy: 0.3043\n",
            "Epoch 63/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 3.2056 - accuracy: 0.3062\n",
            "Epoch 64/100\n",
            "841/841 [==============================] - 11s 14ms/step - loss: 3.1839 - accuracy: 0.3113\n",
            "Epoch 65/100\n",
            "841/841 [==============================] - 11s 14ms/step - loss: 3.1670 - accuracy: 0.3123\n",
            "Epoch 66/100\n",
            "841/841 [==============================] - 11s 14ms/step - loss: 3.1466 - accuracy: 0.3160\n",
            "Epoch 67/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 3.1324 - accuracy: 0.3188\n",
            "Epoch 68/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 3.1137 - accuracy: 0.3207\n",
            "Epoch 69/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 3.0993 - accuracy: 0.3230\n",
            "Epoch 70/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 3.0791 - accuracy: 0.3279\n",
            "Epoch 71/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 3.0606 - accuracy: 0.3297\n",
            "Epoch 72/100\n",
            "841/841 [==============================] - 11s 14ms/step - loss: 3.0433 - accuracy: 0.3334\n",
            "Epoch 73/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 3.0309 - accuracy: 0.3344\n",
            "Epoch 74/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 3.0102 - accuracy: 0.3385\n",
            "Epoch 75/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.9983 - accuracy: 0.3397\n",
            "Epoch 76/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.9817 - accuracy: 0.3422\n",
            "Epoch 77/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.9648 - accuracy: 0.3459\n",
            "Epoch 78/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.9486 - accuracy: 0.3489\n",
            "Epoch 79/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.9320 - accuracy: 0.3512\n",
            "Epoch 80/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.9120 - accuracy: 0.3544\n",
            "Epoch 81/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.8962 - accuracy: 0.3573\n",
            "Epoch 82/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.8843 - accuracy: 0.3596\n",
            "Epoch 83/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.8709 - accuracy: 0.3604\n",
            "Epoch 84/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.8489 - accuracy: 0.3657\n",
            "Epoch 85/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.8364 - accuracy: 0.3676\n",
            "Epoch 86/100\n",
            "841/841 [==============================] - 12s 14ms/step - loss: 2.8232 - accuracy: 0.3701\n",
            "Epoch 87/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.8063 - accuracy: 0.3748\n",
            "Epoch 88/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.7878 - accuracy: 0.3762\n",
            "Epoch 89/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.7770 - accuracy: 0.3778\n",
            "Epoch 90/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.7581 - accuracy: 0.3807\n",
            "Epoch 91/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.7477 - accuracy: 0.3833\n",
            "Epoch 92/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.7323 - accuracy: 0.3863\n",
            "Epoch 93/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.7131 - accuracy: 0.3885\n",
            "Epoch 94/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.7000 - accuracy: 0.3918\n",
            "Epoch 95/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.6870 - accuracy: 0.3941\n",
            "Epoch 96/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.6756 - accuracy: 0.3961\n",
            "Epoch 97/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.6607 - accuracy: 0.3981\n",
            "Epoch 98/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.6464 - accuracy: 0.4022\n",
            "Epoch 99/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.6323 - accuracy: 0.4037\n",
            "Epoch 100/100\n",
            "841/841 [==============================] - 11s 13ms/step - loss: 2.6192 - accuracy: 0.4058\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0bad5c7dc0>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, batch_size=128, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qS0KSrbM1oJn"
      },
      "outputs": [],
      "source": [
        "model.save('nextWordModel.h5')\n",
        "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Model And Use it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZSl25f870M3",
        "outputId": "09682b58-4d01-4b39-8ff3-36c8c80b960f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = load_model('nextWordModel.h5')\n",
        "tokenizer = load(open('tokenizer.pkl', 'rb'))\n",
        "lines = load_doc('r1661-0_sequences.txt').split('\\n')\n",
        "wordsintok = {i: word for word, i in tokenizer.word_index.items()}\n",
        "\n",
        "seq_length = len(lines[0].split()) - 1\n",
        "seq_length"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test for next Word of seed text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgqMiTi48uw3",
        "outputId": "ff2a4f3a-525b-4607-b322-22f039a1c60b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('without paying any fees or charges if you are '\n",
            " 'redistributing or providing access to a work '\n",
            " 'with the phrase project gutenberg associated '\n",
            " 'with or appearing on the work you must comply '\n",
            " 'either with the requirements of paragraphs '\n",
            " 'through or obtain permission for the use of '\n",
            " 'the work and the project gutenberg')\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "\n",
            "('without paying any fees or charges if you are redistributing or providing '\n",
            " 'access to a work with the phrase project gutenberg associated with or '\n",
            " 'appearing on the work you must comply either with the requirements of '\n",
            " 'paragraphs through or obtain permission for the use of the work and the '\n",
            " 'project')\n",
            "gutenberg\n"
          ]
        }
      ],
      "source": [
        "seed_text = random.choice(lines)\n",
        "\n",
        "pprint.pprint(seed_text, width=50)\n",
        "encoded = tokenizer.texts_to_sequences([seed_text])[0][:-1]\n",
        "\n",
        "yhat = model.predict([encoded])\n",
        "\n",
        "classi = np.argmax(yhat)\n",
        "\n",
        "print()\n",
        "pprint.pp(' '.join(seed_text.split(' ')[:-1]))\n",
        "print(wordsintok[classi])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Genrate Sequence of num words After Seed text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "IMekIcBEkjQD"
      },
      "outputs": [],
      "source": [
        "def gen_seq(model, tokenizer, seq_len, seed_text, n_words):\n",
        "    result = []\n",
        "    in_text = seed_text\n",
        "    for _ in range(n_words):\n",
        "        encodedtxt = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\n",
        "        encodedtxt = pad_sequences(\n",
        "            [encodedtxt], maxlen=seq_len, truncating='pre')\n",
        "\n",
        "        yhat = model.predict([encodedtxt])\n",
        "        classi = np.argmax(yhat)\n",
        "        nxtWord = wordsintok[classi]\n",
        "        in_text += ' ' + nxtWord\n",
        "\n",
        "        result.append(nxtWord)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6h5jw4UkjQD",
        "outputId": "07ef3885-9e5b-416e-d6db-f65fc13ef3bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 662ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "\n",
            "This is Seed Text: \n",
            "('of it and how have you succeeded well you have a clue i have them in the '\n",
            " 'hollow of my hand young openshaw shall not long remain unavenged why watson '\n",
            " 'let us put their own devilish trade mark upon them it is well thought of '\n",
            " 'what do you mean he took')\n",
            "\n",
            "This Next 50 Words of Seed Text: \n",
            "('a little cry of satisfaction to say the envelope and the creaking of the '\n",
            " 'countess of morcar the blind that tend to make up the stone in the centre of '\n",
            " 'the table and wondering lazily who two minor important narrative which led '\n",
            " 'out into the frosty air remember to be')\n"
          ]
        }
      ],
      "source": [
        "seed_text = random.choice(lines)\n",
        "\n",
        "gented_txt = gen_seq(model, tokenizer, 50, seed_text, 50)\n",
        "print('\\nThis is Seed Text: ')\n",
        "pprint.pp(seed_text)\n",
        "\n",
        "print('\\nThis Next 50 Words of Seed Text: ')\n",
        "pprint.pp(' '.join(gented_txt))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preidicat the top most num of next words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7ZUV7j4kkjQD"
      },
      "outputs": [],
      "source": [
        "def next_word_rec(model, tokenizer, seq_len, seed_text, n_words):\n",
        "\n",
        "    encodedtxt = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "    encodedtxt = pad_sequences(\n",
        "        [encodedtxt], maxlen=seq_len, truncating='pre')\n",
        "\n",
        "    yhat = model.predict([encodedtxt])\n",
        "    classi = np.argsort(yhat)[0][::-1][:n_words]\n",
        "\n",
        "    return [wordsintok[wordi] for wordi in classi]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hkNMxa8kjQD",
        "outputId": "b42b5de4-215b-4e3a-f138-d19a6c64cd54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "This is Seed Text: \n",
            "('reward offered of is certainly not within a twentieth part of the market '\n",
            " 'price a thousand pounds great lord of mercy the commissionaire plumped down '\n",
            " 'into a chair and stared from one to the other of us that is the reward and i '\n",
            " 'have reason to know that there are sentimental')\n",
            "\n",
            "Top Next 5 Words of Seed Text: considerations, vague, essential, persuaded, as\n"
          ]
        }
      ],
      "source": [
        "seed_text = random.choice(lines)\n",
        "\n",
        "top5nextword = next_word_rec(model, tokenizer, 50, seed_text, 5)\n",
        "print('\\nThis is Seed Text: ')\n",
        "pprint.pp(seed_text)\n",
        "\n",
        "print(f'\\nTop Next 5 Words of Seed Text: {\", \".join(top5nextword)}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Thanks\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
