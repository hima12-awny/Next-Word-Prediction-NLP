{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from numpy import array\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source text\n",
    "data = \"\"\" Jack and Jill went up the hill\\n\n",
    " To fetch a pail of water\\n\n",
    " Jack fell down and broke his crown\\n\n",
    " and Jill came tumbling after\\n \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: one-word-in, one-word-out seq\n",
    "\n",
    "Given one word as input, the model will learn to predict the next word in the sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 22\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "encoded = tokenizer.texts_to_sequences([data])[0]\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f'vocab_size: {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 24\n"
     ]
    }
   ],
   "source": [
    "sequences = [encoded[i-1: i+1] for i in range(1, len(encoded))]\n",
    "print(f'Total Sequences: {len(sequences)}')\n",
    "sequences = array(sequences)\n",
    "\n",
    "X, y = sequences[:, 0], sequences[:, 1]\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1, 10)             220       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 50)                12200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 22)                1122      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13542 (52.90 KB)\n",
      "Trainable params: 13542 (52.90 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 3s - loss: 0.6139 - accuracy: 0.8750 - 3s/epoch - 3s/step\n",
      "Epoch 2/100\n",
      "1/1 - 0s - loss: 0.6089 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "1/1 - 0s - loss: 0.6039 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "1/1 - 0s - loss: 0.5989 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "1/1 - 0s - loss: 0.5940 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 6/100\n",
      "1/1 - 0s - loss: 0.5891 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "1/1 - 0s - loss: 0.5843 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "1/1 - 0s - loss: 0.5795 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 9/100\n",
      "1/1 - 0s - loss: 0.5748 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "1/1 - 0s - loss: 0.5701 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 11/100\n",
      "1/1 - 0s - loss: 0.5655 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 12/100\n",
      "1/1 - 0s - loss: 0.5609 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "1/1 - 0s - loss: 0.5564 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 14/100\n",
      "1/1 - 0s - loss: 0.5519 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 15/100\n",
      "1/1 - 0s - loss: 0.5475 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 16/100\n",
      "1/1 - 0s - loss: 0.5431 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "1/1 - 0s - loss: 0.5388 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "1/1 - 0s - loss: 0.5345 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "1/1 - 0s - loss: 0.5302 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 20/100\n",
      "1/1 - 0s - loss: 0.5260 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 21/100\n",
      "1/1 - 0s - loss: 0.5219 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 22/100\n",
      "1/1 - 0s - loss: 0.5178 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "1/1 - 0s - loss: 0.5137 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 24/100\n",
      "1/1 - 0s - loss: 0.5097 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 25/100\n",
      "1/1 - 0s - loss: 0.5058 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "1/1 - 0s - loss: 0.5019 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 27/100\n",
      "1/1 - 0s - loss: 0.4980 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "1/1 - 0s - loss: 0.4942 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 29/100\n",
      "1/1 - 0s - loss: 0.4904 - accuracy: 0.8750 - 16ms/epoch - 16ms/step\n",
      "Epoch 30/100\n",
      "1/1 - 0s - loss: 0.4867 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 31/100\n",
      "1/1 - 0s - loss: 0.4830 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "1/1 - 0s - loss: 0.4793 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "1/1 - 0s - loss: 0.4757 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 34/100\n",
      "1/1 - 0s - loss: 0.4722 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "1/1 - 0s - loss: 0.4687 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "1/1 - 0s - loss: 0.4652 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "1/1 - 0s - loss: 0.4618 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 38/100\n",
      "1/1 - 0s - loss: 0.4584 - accuracy: 0.8750 - 4ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "1/1 - 0s - loss: 0.4550 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 40/100\n",
      "1/1 - 0s - loss: 0.4517 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "1/1 - 0s - loss: 0.4485 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "1/1 - 0s - loss: 0.4452 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "1/1 - 0s - loss: 0.4420 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "1/1 - 0s - loss: 0.4389 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 45/100\n",
      "1/1 - 0s - loss: 0.4358 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "1/1 - 0s - loss: 0.4327 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "1/1 - 0s - loss: 0.4297 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "1/1 - 0s - loss: 0.4267 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "1/1 - 0s - loss: 0.4237 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "1/1 - 0s - loss: 0.4208 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 51/100\n",
      "1/1 - 0s - loss: 0.4179 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 52/100\n",
      "1/1 - 0s - loss: 0.4150 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "1/1 - 0s - loss: 0.4122 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "1/1 - 0s - loss: 0.4094 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 55/100\n",
      "1/1 - 0s - loss: 0.4067 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "1/1 - 0s - loss: 0.4040 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 57/100\n",
      "1/1 - 0s - loss: 0.4013 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "1/1 - 0s - loss: 0.3986 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "1/1 - 0s - loss: 0.3960 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 60/100\n",
      "1/1 - 0s - loss: 0.3934 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 61/100\n",
      "1/1 - 0s - loss: 0.3909 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "1/1 - 0s - loss: 0.3884 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "1/1 - 0s - loss: 0.3859 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 64/100\n",
      "1/1 - 0s - loss: 0.3834 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 65/100\n",
      "1/1 - 0s - loss: 0.3810 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 66/100\n",
      "1/1 - 0s - loss: 0.3786 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 67/100\n",
      "1/1 - 0s - loss: 0.3762 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 68/100\n",
      "1/1 - 0s - loss: 0.3739 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 69/100\n",
      "1/1 - 0s - loss: 0.3716 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 70/100\n",
      "1/1 - 0s - loss: 0.3693 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 71/100\n",
      "1/1 - 0s - loss: 0.3670 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 72/100\n",
      "1/1 - 0s - loss: 0.3648 - accuracy: 0.8750 - 15ms/epoch - 15ms/step\n",
      "Epoch 73/100\n",
      "1/1 - 0s - loss: 0.3626 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 74/100\n",
      "1/1 - 0s - loss: 0.3605 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 75/100\n",
      "1/1 - 0s - loss: 0.3583 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 76/100\n",
      "1/1 - 0s - loss: 0.3562 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 77/100\n",
      "1/1 - 0s - loss: 0.3541 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 78/100\n",
      "1/1 - 0s - loss: 0.3521 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 79/100\n",
      "1/1 - 0s - loss: 0.3500 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 80/100\n",
      "1/1 - 0s - loss: 0.3480 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 81/100\n",
      "1/1 - 0s - loss: 0.3460 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 82/100\n",
      "1/1 - 0s - loss: 0.3441 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 83/100\n",
      "1/1 - 0s - loss: 0.3422 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 84/100\n",
      "1/1 - 0s - loss: 0.3402 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 85/100\n",
      "1/1 - 0s - loss: 0.3384 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
      "Epoch 86/100\n",
      "1/1 - 0s - loss: 0.3365 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 87/100\n",
      "1/1 - 0s - loss: 0.3347 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 88/100\n",
      "1/1 - 0s - loss: 0.3329 - accuracy: 0.8750 - 16ms/epoch - 16ms/step\n",
      "Epoch 89/100\n",
      "1/1 - 0s - loss: 0.3311 - accuracy: 0.8750 - 16ms/epoch - 16ms/step\n",
      "Epoch 90/100\n",
      "1/1 - 0s - loss: 0.3293 - accuracy: 0.8750 - 16ms/epoch - 16ms/step\n",
      "Epoch 91/100\n",
      "1/1 - 0s - loss: 0.3276 - accuracy: 0.8750 - 16ms/epoch - 16ms/step\n",
      "Epoch 92/100\n",
      "1/1 - 0s - loss: 0.3259 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 93/100\n",
      "1/1 - 0s - loss: 0.3242 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 94/100\n",
      "1/1 - 0s - loss: 0.3225 - accuracy: 0.8750 - 16ms/epoch - 16ms/step\n",
      "Epoch 95/100\n",
      "1/1 - 0s - loss: 0.3209 - accuracy: 0.8750 - 16ms/epoch - 16ms/step\n",
      "Epoch 96/100\n",
      "1/1 - 0s - loss: 0.3193 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 97/100\n",
      "1/1 - 0s - loss: 0.3177 - accuracy: 0.8750 - 16ms/epoch - 16ms/step\n",
      "Epoch 98/100\n",
      "1/1 - 0s - loss: 0.3161 - accuracy: 0.8750 - 16ms/epoch - 16ms/step\n",
      "Epoch 99/100\n",
      "1/1 - 0s - loss: 0.3145 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
      "Epoch 100/100\n",
      "1/1 - 0s - loss: 0.3130 - accuracy: 0.8750 - 16ms/epoch - 16ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X, y, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c1c40d6ed0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgyklEQVR4nO3df1DUdeLH8deC8qNToFSWIAzznKw0JdE9sLnrJibKjqvO6SxJka48C0ylqUMFLR3Fm7th6NS0muyc1NOa1LoyGwfT4o5AQbs8fw+NMiQg18kaJir7/v7xnbbvfgVjEd039HzM7Mz12ffns+/Pe27kOZ/97K7DGGMEAABgsaBATwAAAOCHECwAAMB6BAsAALAewQIAAKxHsAAAAOsRLAAAwHoECwAAsB7BAgAArNcr0BPoKh6PR1999ZX69u0rh8MR6OkAAIAOMMbo9OnTio2NVVBQ+9dRekywfPXVV4qPjw/0NAAAQCfU1NTohhtuaPf5HhMsffv2lfS/JxwRERHg2QAAgI5wu92Kj4/3/h1vT48Jlu/eBoqIiCBYAADoZn7odg5uugUAANYjWAAAgPUIFgAAYD2CBQAAWK9TwbJ8+XIlJCQoLCxMLpdLFRUV7Y49f/68FixYoMGDByssLEwjRozQ1q1bfcYUFhZq9OjR6tu3r6Kjo/Xggw/q0KFDnZkaAADogfwOlg0bNig3N1fz589XVVWVRowYobS0NDU0NLQ5Pj8/X6+88oqWLl2q/fv3a9q0aXrooYe0Z88e75idO3cqOztbn332mbZt26bz58/rnnvuUXNzc+fPDAAA9BgOY4zxZweXy6XRo0dr2bJlkv73G2bj4+M1ffp05eXlXTQ+NjZWc+fOVXZ2tnfb+PHjFR4erjVr1rT5GidPnlR0dLR27typn//85x2al9vtVmRkpJqamvhYMwAA3URH/377dYXl3LlzqqysVGpq6vcHCApSamqqysrK2tynpaVFYWFhPtvCw8NVWlra7us0NTVJkq677jp/pgcAAHoov4KlsbFRra2tcjqdPtudTqfq6ura3CctLU1FRUU6cuSIPB6Ptm3bpo0bN+rEiRNtjvd4PJo5c6bGjh2rYcOGtTuXlpYWud1unwcAAOiZrvinhF566SUNGTJEQ4cOVUhIiHJycpSVldXuDxxlZ2dr3759Wr9+/SWPW1hYqMjISO+D3xECAKDn8itY+vfvr+DgYNXX1/tsr6+vV0xMTJv7DBgwQJs3b1Zzc7OOHTumgwcPqk+fPrrpppsuGpuTk6P3339fH3/88SV/AEmSZs+eraamJu+jpqbGn1MBAADdiF/BEhISolGjRqmkpMS7zePxqKSkRMnJyZfcNywsTHFxcbpw4YLeeecdPfDAA97njDHKycnRpk2btH37dg0aNOgH5xIaGur93SB+PwgAgJ7N7x8/zM3NVWZmppKSkjRmzBgVFxerublZWVlZkqTJkycrLi5OhYWFkqTy8nLV1tZq5MiRqq2t1QsvvCCPx6Pnn3/ee8zs7GytW7dO7777rvr27eu9HyYyMlLh4eFdcZ4AAKAb8ztYJkyYoJMnT2revHmqq6vTyJEjtXXrVu+NuMePH/e5P+Xs2bPKz89XdXW1+vTpo3HjxunNN99UVFSUd8yKFSskSXfddZfPa73xxhuaMmWK/2cFAAB6FL+/h8VWfA8LAADdzxX5HhYAAIBAIFgAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPU6FSzLly9XQkKCwsLC5HK5VFFR0e7Y8+fPa8GCBRo8eLDCwsI0YsQIbd269bKOCQAAflz8DpYNGzYoNzdX8+fPV1VVlUaMGKG0tDQ1NDS0OT4/P1+vvPKKli5dqv3792vatGl66KGHtGfPnk4fEwAA/Lg4jDHGnx1cLpdGjx6tZcuWSZI8Ho/i4+M1ffp05eXlXTQ+NjZWc+fOVXZ2tnfb+PHjFR4erjVr1nTqmG1xu92KjIxUU1OTIiIi/DklAAAQIB39++3XFZZz586psrJSqamp3x8gKEipqakqKytrc5+WlhaFhYX5bAsPD1dpaWmnj/ndcd1ut88DAAD0TH4FS2Njo1pbW+V0On22O51O1dXVtblPWlqaioqKdOTIEXk8Hm3btk0bN27UiRMnOn1MSSosLFRkZKT3ER8f78+pAACAbuSKf0ropZde0pAhQzR06FCFhIQoJydHWVlZCgq6vJeePXu2mpqavI+ampoumjEAALCNX9XQv39/BQcHq76+3md7fX29YmJi2txnwIAB2rx5s5qbm3Xs2DEdPHhQffr00U033dTpY0pSaGioIiIifB4AAKBn8itYQkJCNGrUKJWUlHi3eTwelZSUKDk5+ZL7hoWFKS4uThcuXNA777yjBx544LKPCQAAfhx6+btDbm6uMjMzlZSUpDFjxqi4uFjNzc3KysqSJE2ePFlxcXEqLCyUJJWXl6u2tlYjR45UbW2tXnjhBXk8Hj3//PMdPiYAAPhx8ztYJkyYoJMnT2revHmqq6vTyJEjtXXrVu9Ns8ePH/e5P+Xs2bPKz89XdXW1+vTpo3HjxunNN99UVFRUh48JAAB+3Pz+HhZb8T0sAAB0P1fke1gAAAACgWABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANbrVLAsX75cCQkJCgsLk8vlUkVFxSXHFxcX6+abb1Z4eLji4+M1a9YsnT171vt8a2urCgoKNGjQIIWHh2vw4MFauHChjDGdmR4AAOhhevm7w4YNG5Sbm6uVK1fK5XKpuLhYaWlpOnTokKKjoy8av27dOuXl5WnVqlVKSUnR4cOHNWXKFDkcDhUVFUmS/vjHP2rFihVavXq1brvtNu3evVtZWVmKjIzUM888c/lnCQAAujWH8fMyhsvl0ujRo7Vs2TJJksfjUXx8vKZPn668vLyLxufk5OjAgQMqKSnxbnv22WdVXl6u0tJSSdKvfvUrOZ1Ovf76694x48ePV3h4uNasWdOhebndbkVGRqqpqUkRERH+nBIAAAiQjv799ustoXPnzqmyslKpqanfHyAoSKmpqSorK2tzn5SUFFVWVnrfNqqurtaWLVs0btw4nzElJSU6fPiwJOnzzz9XaWmp7rvvvnbn0tLSIrfb7fMAAAA9k19vCTU2Nqq1tVVOp9Nnu9Pp1MGDB9vcZ+LEiWpsbNSdd94pY4wuXLigadOmac6cOd4xeXl5crvdGjp0qIKDg9Xa2qpFixYpIyOj3bkUFhbqxRdf9Gf6AACgm7rinxLasWOHFi9erJdffllVVVXauHGjPvjgAy1cuNA75q233tLatWu1bt06VVVVafXq1frzn/+s1atXt3vc2bNnq6mpyfuoqam50qcCAAACxK8rLP3791dwcLDq6+t9ttfX1ysmJqbNfQoKCjRp0iQ98cQTkqThw4erublZU6dO1dy5cxUUFKTnnntOeXl5euSRR7xjjh07psLCQmVmZrZ53NDQUIWGhvozfQAA0E35dYUlJCREo0aN8rmB1uPxqKSkRMnJyW3uc+bMGQUF+b5McHCwJHk/ttzeGI/H48/0AABAD+X3x5pzc3OVmZmppKQkjRkzRsXFxWpublZWVpYkafLkyYqLi1NhYaEkKT09XUVFRUpMTJTL5dLRo0dVUFCg9PR0b7ikp6dr0aJFGjhwoG677Tbt2bNHRUVFevzxx7vwVAEAQHfld7BMmDBBJ0+e1Lx581RXV6eRI0dq69at3htxjx8/7nO1JD8/Xw6HQ/n5+aqtrdWAAQO8gfKdpUuXqqCgQE8//bQaGhoUGxur3//+95o3b14XnCIAAOju/P4eFlvxPSwAAHQ/V+R7WAAAAAKBYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADW8/u3hH5MjDH69nxroKcBAIAVwnsHy+FwBOS1CZZL+PZ8q26d91GgpwEAgBX2L0jTNSGBSQfeEgIAANbjCsslhPcO1v4FaYGeBgAAVgjvHRyw1yZYLsHhcATs0hcAAPgebwkBAADrESwAAMB6BAsAALAewQIAAKxHsAAAAOsRLAAAwHoECwAAsB7BAgAArEewAAAA6xEsAADAegQLAACwHsECAACsR7AAAADrESwAAMB6BAsAALAewQIAAKxHsAAAAOsRLAAAwHoECwAAsB7BAgAArEewAAAA6xEsAADAegQLAACwHsECAACsR7AAAADrESwAAMB6BAsAALAewQIAAKxHsAAAAOsRLAAAwHoECwAAsB7BAgAArEewAAAA6xEsAADAegQLAACwHsECAACsR7AAAADrESwAAMB6BAsAALAewQIAAKxHsAAAAOsRLAAAwHoECwAAsB7BAgAArEewAAAA6xEsAADAegQLAACwHsECAACsR7AAAADrESwAAMB6BAsAALBep4Jl+fLlSkhIUFhYmFwulyoqKi45vri4WDfffLPCw8MVHx+vWbNm6ezZsz5jamtr9dhjj6lfv34KDw/X8OHDtXv37s5MDwAA9DC9/N1hw4YNys3N1cqVK+VyuVRcXKy0tDQdOnRI0dHRF41ft26d8vLytGrVKqWkpOjw4cOaMmWKHA6HioqKJEn//e9/NXbsWP3yl7/Uhx9+qAEDBujIkSO69tprL/8MAQBAt+cwxhh/dnC5XBo9erSWLVsmSfJ4PIqPj9f06dOVl5d30ficnBwdOHBAJSUl3m3PPvusysvLVVpaKknKy8vTP/7xD3366aedPhG3263IyEg1NTUpIiKi08cBAABXT0f/fvv1ltC5c+dUWVmp1NTU7w8QFKTU1FSVlZW1uU9KSooqKyu9bxtVV1dry5YtGjdunHfMe++9p6SkJD388MOKjo5WYmKiXnvttUvOpaWlRW632+cBAAB6Jr+CpbGxUa2trXI6nT7bnU6n6urq2txn4sSJWrBgge6880717t1bgwcP1l133aU5c+Z4x1RXV2vFihUaMmSIPvroIz311FN65plntHr16nbnUlhYqMjISO8jPj7en1MBAADdyBX/lNCOHTu0ePFivfzyy6qqqtLGjRv1wQcfaOHChd4xHo9Hd9xxhxYvXqzExERNnTpVTz75pFauXNnucWfPnq2mpibvo6am5kqfCgAACBC/brrt37+/goODVV9f77O9vr5eMTExbe5TUFCgSZMm6YknnpAkDR8+XM3NzZo6darmzp2roKAgXX/99br11lt99rvlllv0zjvvtDuX0NBQhYaG+jN9AADQTfl1hSUkJESjRo3yuYHW4/GopKREycnJbe5z5swZBQX5vkxwcLAk6bv7fceOHatDhw75jDl8+LBuvPFGf6YHAAB6KL8/1pybm6vMzEwlJSVpzJgxKi4uVnNzs7KysiRJkydPVlxcnAoLCyVJ6enpKioqUmJiolwul44ePaqCggKlp6d7w2XWrFlKSUnR4sWL9dvf/lYVFRV69dVX9eqrr3bhqQIAgO7K72CZMGGCTp48qXnz5qmurk4jR47U1q1bvTfiHj9+3OeKSn5+vhwOh/Lz81VbW6sBAwYoPT1dixYt8o4ZPXq0Nm3apNmzZ2vBggUaNGiQiouLlZGR0QWnCAAAuju/v4fFVnwPCwAA3c8V+R4WAACAQCBYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1OhUsy5cvV0JCgsLCwuRyuVRRUXHJ8cXFxbr55psVHh6u+Ph4zZo1S2fPnm1z7JIlS+RwODRz5szOTA0AAPRAfgfLhg0blJubq/nz56uqqkojRoxQWlqaGhoa2hy/bt065eXlaf78+Tpw4IBef/11bdiwQXPmzLlo7K5du/TKK6/o9ttv9/9MAABAj+V3sBQVFenJJ59UVlaWbr31Vq1cuVLXXHONVq1a1eb4f/7znxo7dqwmTpyohIQE3XPPPXr00UcvuirzzTffKCMjQ6+99pquvfbazp0NAADokfwKlnPnzqmyslKpqanfHyAoSKmpqSorK2tzn5SUFFVWVnoDpbq6Wlu2bNG4ceN8xmVnZ+v+++/3OfaltLS0yO12+zwAAEDP1MufwY2NjWptbZXT6fTZ7nQ6dfDgwTb3mThxohobG3XnnXfKGKMLFy5o2rRpPm8JrV+/XlVVVdq1a1eH51JYWKgXX3zRn+kDAIBu6op/SmjHjh1avHixXn75ZVVVVWnjxo364IMPtHDhQklSTU2NZsyYobVr1yosLKzDx509e7aampq8j5qamit1CgAAIMD8usLSv39/BQcHq76+3md7fX29YmJi2tynoKBAkyZN0hNPPCFJGj58uJqbmzV16lTNnTtXlZWVamho0B133OHdp7W1VZ988omWLVumlpYWBQcHX3Tc0NBQhYaG+jN9AADQTfl1hSUkJESjRo1SSUmJd5vH41FJSYmSk5Pb3OfMmTMKCvJ9me8CxBiju+++W1988YX27t3rfSQlJSkjI0N79+5tM1YAAMCPi19XWCQpNzdXmZmZSkpK0pgxY1RcXKzm5mZlZWVJkiZPnqy4uDgVFhZKktLT01VUVKTExES5XC4dPXpUBQUFSk9PV3BwsPr27athw4b5vMZPfvIT9evX76LtAADgx8nvYJkwYYJOnjypefPmqa6uTiNHjtTWrVu9N+IeP37c54pKfn6+HA6H8vPzVVtbqwEDBig9PV2LFi3qurMAAAA9msMYYwI9ia7gdrsVGRmppqYmRUREBHo6AACgAzr695vfEgIAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9XoFegJdxRgjSXK73QGeCQAA6Kjv/m5/93e8PT0mWE6fPi1Jio+PD/BMAACAv06fPq3IyMh2n3eYH0qabsLj8eirr75S37595XA4uuy4brdb8fHxqqmpUURERJcdFxdjra8e1vrqYa2vLtb76umqtTbG6PTp04qNjVVQUPt3qvSYKyxBQUG64YYbrtjxIyIi+D//VcJaXz2s9dXDWl9drPfV0xVrfakrK9/hplsAAGA9ggUAAFiPYPkBoaGhmj9/vkJDQwM9lR6Ptb56WOurh7W+uljvq+dqr3WPuekWAAD0XFxhAQAA1iNYAACA9QgWAABgPYIFAABYj2D5AcuXL1dCQoLCwsLkcrlUUVER6Cl1a4WFhRo9erT69u2r6OhoPfjggzp06JDPmLNnzyo7O1v9+vVTnz59NH78eNXX1wdoxj3HkiVL5HA4NHPmTO821rpr1dbW6rHHHlO/fv0UHh6u4cOHa/fu3d7njTGaN2+err/+eoWHhys1NVVHjhwJ4Iy7p9bWVhUUFGjQoEEKDw/X4MGDtXDhQp/fomGtO+eTTz5Renq6YmNj5XA4tHnzZp/nO7KuX3/9tTIyMhQREaGoqCj97ne/0zfffHP5kzNo1/r1601ISIhZtWqV+fe//22efPJJExUVZerr6wM9tW4rLS3NvPHGG2bfvn1m7969Zty4cWbgwIHmm2++8Y6ZNm2aiY+PNyUlJWb37t3mZz/7mUlJSQngrLu/iooKk5CQYG6//XYzY8YM73bWuut8/fXX5sYbbzRTpkwx5eXlprq62nz00Ufm6NGj3jFLliwxkZGRZvPmzebzzz83v/71r82gQYPMt99+G8CZdz+LFi0y/fr1M++//7758ssvzdtvv2369OljXnrpJe8Y1rpztmzZYubOnWs2btxoJJlNmzb5PN+Rdb333nvNiBEjzGeffWY+/fRT89Of/tQ8+uijlz03guUSxowZY7Kzs73/3draamJjY01hYWEAZ9WzNDQ0GElm586dxhhjTp06ZXr37m3efvtt75gDBw4YSaasrCxQ0+zWTp8+bYYMGWK2bdtmfvGLX3iDhbXuWn/4wx/MnXfe2e7zHo/HxMTEmD/96U/ebadOnTKhoaHmb3/729WYYo9x//33m8cff9xn229+8xuTkZFhjGGtu8r/D5aOrOv+/fuNJLNr1y7vmA8//NA4HA5TW1t7WfPhLaF2nDt3TpWVlUpNTfVuCwoKUmpqqsrKygI4s56lqalJknTddddJkiorK3X+/HmfdR86dKgGDhzIundSdna27r//fp81lVjrrvbee+8pKSlJDz/8sKKjo5WYmKjXXnvN+/yXX36puro6n/WOjIyUy+Vivf2UkpKikpISHT58WJL0+eefq7S0VPfdd58k1vpK6ci6lpWVKSoqSklJSd4xqampCgoKUnl5+WW9fo/58cOu1tjYqNbWVjmdTp/tTqdTBw8eDNCsehaPx6OZM2dq7NixGjZsmCSprq5OISEhioqK8hnrdDpVV1cXgFl2b+vXr1dVVZV27dp10XOsddeqrq7WihUrlJubqzlz5mjXrl165plnFBISoszMTO+atvVvCuvtn7y8PLndbg0dOlTBwcFqbW3VokWLlJGRIUms9RXSkXWtq6tTdHS0z/O9evXSddddd9lrT7AgYLKzs7Vv3z6VlpYGeio9Uk1NjWbMmKFt27YpLCws0NPp8Twej5KSkrR48WJJUmJiovbt26eVK1cqMzMzwLPrWd566y2tXbtW69at02233aa9e/dq5syZio2NZa17MN4Sakf//v0VHBx80Scm6uvrFRMTE6BZ9Rw5OTl6//339fHHH+uGG27wbo+JidG5c+d06tQpn/Gsu/8qKyvV0NCgO+64Q7169VKvXr20c+dO/eUvf1GvXr3kdDpZ6y50/fXX69Zbb/XZdsstt+j48eOS5F1T/k25fM8995zy8vL0yCOPaPjw4Zo0aZJmzZqlwsJCSaz1ldKRdY2JiVFDQ4PP8xcuXNDXX3992WtPsLQjJCREo0aNUklJiXebx+NRSUmJkpOTAziz7s0Yo5ycHG3atEnbt2/XoEGDfJ4fNWqUevfu7bPuhw4d0vHjx1l3P91999364osvtHfvXu8jKSlJGRkZ3v/NWnedsWPHXvQR/cOHD+vGG2+UJA0aNEgxMTE+6+12u1VeXs56++nMmTMKCvL98xUcHCyPxyOJtb5SOrKuycnJOnXqlCorK71jtm/fLo/HI5fLdXkTuKxbdnu49evXm9DQUPPXv/7V7N+/30ydOtVERUWZurq6QE+t23rqqadMZGSk2bFjhzlx4oT3cebMGe+YadOmmYEDB5rt27eb3bt3m+TkZJOcnBzAWfcc//dTQsaw1l2poqLC9OrVyyxatMgcOXLErF271lxzzTVmzZo13jFLliwxUVFR5t133zX/+te/zAMPPMBHbTshMzPTxMXFeT/WvHHjRtO/f3/z/PPPe8ew1p1z+vRps2fPHrNnzx4jyRQVFZk9e/aYY8eOGWM6tq733nuvSUxMNOXl5aa0tNQMGTKEjzVfDUuXLjUDBw40ISEhZsyYMeazzz4L9JS6NUltPt544w3vmG+//dY8/fTT5tprrzXXXHONeeihh8yJEycCN+ke5P8HC2vdtf7+97+bYcOGmdDQUDN06FDz6quv+jzv8XhMQUGBcTqdJjQ01Nx9993m0KFDAZpt9+V2u82MGTPMwIEDTVhYmLnpppvM3LlzTUtLi3cMa905H3/8cZv/RmdmZhpjOrau//nPf8yjjz5q+vTpYyIiIkxWVpY5ffr0Zc/NYcz/+WpAAAAAC3EPCwAAsB7BAgAArEewAAAA6xEsAADAegQLAACwHsECAACsR7AAAADrESwAAMB6BAsAALAewQIAAKxHsAAAAOsRLAAAwHr/Aw0/aVKTLamIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_text : fell\n",
      "out_text: down\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "in_text = random.choice(list(tokenizer.word_index.keys()))\n",
    "print(f'in_text : {in_text}')\n",
    "\n",
    "seq = array(tokenizer.texts_to_sequences([in_text])[0])\n",
    "yhat = model.predict_on_batch([seq])\n",
    "out_text = tokenizer.index_word[np.argmax(yhat)]\n",
    "print(f'out_text: {out_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_seq(model, tokenizer, seed_text, n_words):\n",
    "    in_text, res = seed_text, seed_text\n",
    "    for _ in range(n_words):\n",
    "        seq = array(tokenizer.texts_to_sequences([in_text])[0])\n",
    "        yhat = model.predict_on_batch([seq])\n",
    "        out_text = tokenizer.index_word[np.argmax(yhat)]\n",
    "        in_text, res = out_text, res + ' ' + out_text\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next seq: fell down and jill came tumbling\n"
     ]
    }
   ],
   "source": [
    "in_text = random.choice(list(tokenizer.word_index.keys()))\n",
    "\n",
    "next_pre_seq = gen_seq(model, tokenizer, in_text, 5)\n",
    "print(f'next seq:', next_pre_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_next_word(model, tokenizer, seed_text, n_words):\n",
    "\n",
    "    seq = array(tokenizer.texts_to_sequences([seed_text])[0])\n",
    "    yhat = model.predict_on_batch([seq])\n",
    "\n",
    "    out_text = [tokenizer.index_word[i]\n",
    "                for i in np.argsort(yhat)[0][::-1][:n_words]]\n",
    "\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Jack and Jill went up the hill\n",
      "\n",
      " To fetch a pail of water\n",
      "\n",
      " Jack fell down and broke his crown\n",
      "\n",
      " and Jill came tumbling after\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most prop for next words after <jill>: ['came', 'went', 'down', 'jill', 'broke']\n"
     ]
    }
   ],
   "source": [
    "in_text = random.choice(list(tokenizer.word_index.keys()))\n",
    "\n",
    "most_porp_next_word = gen_next_word(model, tokenizer, in_text, 5)\n",
    "print(\n",
    "    f'Top 5 most prop for next words after <{in_text}>: {most_porp_next_word}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Line-by-Line Sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 21\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sequences = []\n",
    "\n",
    "for line in data.split('\\n'):\n",
    "    \n",
    "    encoded = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequences.append(encoded[:i+1])\n",
    "\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 7\n"
     ]
    }
   ],
   "source": [
    "max_len = max([len(s) for s in sequences])\n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
    "sequences = array(sequences)\n",
    "print('Max Sequence Length: %d' % max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sequences[:, :-1], sequences[:, -1]\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 6, 10)             220       \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                12200     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 22)                1122      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13542 (52.90 KB)\n",
      "Trainable params: 13542 (52.90 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "1/1 - 3s - loss: 3.0914 - accuracy: 0.0476 - 3s/epoch - 3s/step\n",
      "Epoch 2/300\n",
      "1/1 - 0s - loss: 3.0899 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 3/300\n",
      "1/1 - 0s - loss: 3.0883 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 4/300\n",
      "1/1 - 0s - loss: 3.0868 - accuracy: 0.1905 - 12ms/epoch - 12ms/step\n",
      "Epoch 5/300\n",
      "1/1 - 0s - loss: 3.0852 - accuracy: 0.1429 - 16ms/epoch - 16ms/step\n",
      "Epoch 6/300\n",
      "1/1 - 0s - loss: 3.0836 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 7/300\n",
      "1/1 - 0s - loss: 3.0820 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 8/300\n",
      "1/1 - 0s - loss: 3.0803 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 9/300\n",
      "1/1 - 0s - loss: 3.0785 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 10/300\n",
      "1/1 - 0s - loss: 3.0767 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 11/300\n",
      "1/1 - 0s - loss: 3.0748 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 12/300\n",
      "1/1 - 0s - loss: 3.0729 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 13/300\n",
      "1/1 - 0s - loss: 3.0708 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 14/300\n",
      "1/1 - 0s - loss: 3.0687 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 15/300\n",
      "1/1 - 0s - loss: 3.0664 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 16/300\n",
      "1/1 - 0s - loss: 3.0640 - accuracy: 0.0952 - 20ms/epoch - 20ms/step\n",
      "Epoch 17/300\n",
      "1/1 - 0s - loss: 3.0614 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 18/300\n",
      "1/1 - 0s - loss: 3.0588 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 19/300\n",
      "1/1 - 0s - loss: 3.0559 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 20/300\n",
      "1/1 - 0s - loss: 3.0529 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 21/300\n",
      "1/1 - 0s - loss: 3.0496 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 22/300\n",
      "1/1 - 0s - loss: 3.0462 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 23/300\n",
      "1/1 - 0s - loss: 3.0425 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 24/300\n",
      "1/1 - 0s - loss: 3.0385 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 25/300\n",
      "1/1 - 0s - loss: 3.0343 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 26/300\n",
      "1/1 - 0s - loss: 3.0297 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 27/300\n",
      "1/1 - 0s - loss: 3.0248 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 28/300\n",
      "1/1 - 0s - loss: 3.0195 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 29/300\n",
      "1/1 - 0s - loss: 3.0139 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 30/300\n",
      "1/1 - 0s - loss: 3.0077 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 31/300\n",
      "1/1 - 0s - loss: 3.0012 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 32/300\n",
      "1/1 - 0s - loss: 2.9941 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 33/300\n",
      "1/1 - 0s - loss: 2.9864 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 34/300\n",
      "1/1 - 0s - loss: 2.9782 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 35/300\n",
      "1/1 - 0s - loss: 2.9693 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 36/300\n",
      "1/1 - 0s - loss: 2.9598 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 37/300\n",
      "1/1 - 0s - loss: 2.9497 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 38/300\n",
      "1/1 - 0s - loss: 2.9389 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 39/300\n",
      "1/1 - 0s - loss: 2.9275 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 40/300\n",
      "1/1 - 0s - loss: 2.9156 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 41/300\n",
      "1/1 - 0s - loss: 2.9033 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 42/300\n",
      "1/1 - 0s - loss: 2.8906 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 43/300\n",
      "1/1 - 0s - loss: 2.8778 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 44/300\n",
      "1/1 - 0s - loss: 2.8651 - accuracy: 0.0952 - 20ms/epoch - 20ms/step\n",
      "Epoch 45/300\n",
      "1/1 - 0s - loss: 2.8526 - accuracy: 0.0952 - 20ms/epoch - 20ms/step\n",
      "Epoch 46/300\n",
      "1/1 - 0s - loss: 2.8402 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 47/300\n",
      "1/1 - 0s - loss: 2.8278 - accuracy: 0.0952 - 12ms/epoch - 12ms/step\n",
      "Epoch 48/300\n",
      "1/1 - 0s - loss: 2.8150 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 49/300\n",
      "1/1 - 0s - loss: 2.8013 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 50/300\n",
      "1/1 - 0s - loss: 2.7865 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 51/300\n",
      "1/1 - 0s - loss: 2.7705 - accuracy: 0.0952 - 20ms/epoch - 20ms/step\n",
      "Epoch 52/300\n",
      "1/1 - 0s - loss: 2.7533 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 53/300\n",
      "1/1 - 0s - loss: 2.7351 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 54/300\n",
      "1/1 - 0s - loss: 2.7160 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 55/300\n",
      "1/1 - 0s - loss: 2.6962 - accuracy: 0.1429 - 16ms/epoch - 16ms/step\n",
      "Epoch 56/300\n",
      "1/1 - 0s - loss: 2.6758 - accuracy: 0.1429 - 24ms/epoch - 24ms/step\n",
      "Epoch 57/300\n",
      "1/1 - 0s - loss: 2.6547 - accuracy: 0.0952 - 16ms/epoch - 16ms/step\n",
      "Epoch 58/300\n",
      "1/1 - 0s - loss: 2.6328 - accuracy: 0.1429 - 8ms/epoch - 8ms/step\n",
      "Epoch 59/300\n",
      "1/1 - 0s - loss: 2.6097 - accuracy: 0.1905 - 16ms/epoch - 16ms/step\n",
      "Epoch 60/300\n",
      "1/1 - 0s - loss: 2.5854 - accuracy: 0.1905 - 16ms/epoch - 16ms/step\n",
      "Epoch 61/300\n",
      "1/1 - 0s - loss: 2.5597 - accuracy: 0.1905 - 12ms/epoch - 12ms/step\n",
      "Epoch 62/300\n",
      "1/1 - 0s - loss: 2.5327 - accuracy: 0.1905 - 12ms/epoch - 12ms/step\n",
      "Epoch 63/300\n",
      "1/1 - 0s - loss: 2.5044 - accuracy: 0.1905 - 12ms/epoch - 12ms/step\n",
      "Epoch 64/300\n",
      "1/1 - 0s - loss: 2.4752 - accuracy: 0.1905 - 8ms/epoch - 8ms/step\n",
      "Epoch 65/300\n",
      "1/1 - 0s - loss: 2.4453 - accuracy: 0.1905 - 13ms/epoch - 13ms/step\n",
      "Epoch 66/300\n",
      "1/1 - 0s - loss: 2.4148 - accuracy: 0.1905 - 12ms/epoch - 12ms/step\n",
      "Epoch 67/300\n",
      "1/1 - 0s - loss: 2.3839 - accuracy: 0.1905 - 12ms/epoch - 12ms/step\n",
      "Epoch 68/300\n",
      "1/1 - 0s - loss: 2.3526 - accuracy: 0.1905 - 12ms/epoch - 12ms/step\n",
      "Epoch 69/300\n",
      "1/1 - 0s - loss: 2.3208 - accuracy: 0.2381 - 12ms/epoch - 12ms/step\n",
      "Epoch 70/300\n",
      "1/1 - 0s - loss: 2.2887 - accuracy: 0.2381 - 12ms/epoch - 12ms/step\n",
      "Epoch 71/300\n",
      "1/1 - 0s - loss: 2.2564 - accuracy: 0.2381 - 12ms/epoch - 12ms/step\n",
      "Epoch 72/300\n",
      "1/1 - 0s - loss: 2.2241 - accuracy: 0.2381 - 12ms/epoch - 12ms/step\n",
      "Epoch 73/300\n",
      "1/1 - 0s - loss: 2.1917 - accuracy: 0.2381 - 12ms/epoch - 12ms/step\n",
      "Epoch 74/300\n",
      "1/1 - 0s - loss: 2.1593 - accuracy: 0.2381 - 12ms/epoch - 12ms/step\n",
      "Epoch 75/300\n",
      "1/1 - 0s - loss: 2.1271 - accuracy: 0.1905 - 8ms/epoch - 8ms/step\n",
      "Epoch 76/300\n",
      "1/1 - 0s - loss: 2.0953 - accuracy: 0.2381 - 11ms/epoch - 11ms/step\n",
      "Epoch 77/300\n",
      "1/1 - 0s - loss: 2.0636 - accuracy: 0.2857 - 12ms/epoch - 12ms/step\n",
      "Epoch 78/300\n",
      "1/1 - 0s - loss: 2.0321 - accuracy: 0.2857 - 12ms/epoch - 12ms/step\n",
      "Epoch 79/300\n",
      "1/1 - 0s - loss: 2.0010 - accuracy: 0.3333 - 12ms/epoch - 12ms/step\n",
      "Epoch 80/300\n",
      "1/1 - 0s - loss: 1.9704 - accuracy: 0.3333 - 12ms/epoch - 12ms/step\n",
      "Epoch 81/300\n",
      "1/1 - 0s - loss: 1.9402 - accuracy: 0.3810 - 12ms/epoch - 12ms/step\n",
      "Epoch 82/300\n",
      "1/1 - 0s - loss: 1.9106 - accuracy: 0.3810 - 12ms/epoch - 12ms/step\n",
      "Epoch 83/300\n",
      "1/1 - 0s - loss: 1.8820 - accuracy: 0.4286 - 16ms/epoch - 16ms/step\n",
      "Epoch 84/300\n",
      "1/1 - 0s - loss: 1.8542 - accuracy: 0.4762 - 12ms/epoch - 12ms/step\n",
      "Epoch 85/300\n",
      "1/1 - 0s - loss: 1.8273 - accuracy: 0.4762 - 8ms/epoch - 8ms/step\n",
      "Epoch 86/300\n",
      "1/1 - 0s - loss: 1.8013 - accuracy: 0.5238 - 8ms/epoch - 8ms/step\n",
      "Epoch 87/300\n",
      "1/1 - 0s - loss: 1.7756 - accuracy: 0.5714 - 12ms/epoch - 12ms/step\n",
      "Epoch 88/300\n",
      "1/1 - 0s - loss: 1.7506 - accuracy: 0.5714 - 13ms/epoch - 13ms/step\n",
      "Epoch 89/300\n",
      "1/1 - 0s - loss: 1.7259 - accuracy: 0.5714 - 16ms/epoch - 16ms/step\n",
      "Epoch 90/300\n",
      "1/1 - 0s - loss: 1.7017 - accuracy: 0.5714 - 16ms/epoch - 16ms/step\n",
      "Epoch 91/300\n",
      "1/1 - 0s - loss: 1.6777 - accuracy: 0.6667 - 12ms/epoch - 12ms/step\n",
      "Epoch 92/300\n",
      "1/1 - 0s - loss: 1.6541 - accuracy: 0.7143 - 12ms/epoch - 12ms/step\n",
      "Epoch 93/300\n",
      "1/1 - 0s - loss: 1.6308 - accuracy: 0.7143 - 12ms/epoch - 12ms/step\n",
      "Epoch 94/300\n",
      "1/1 - 0s - loss: 1.6076 - accuracy: 0.6667 - 8ms/epoch - 8ms/step\n",
      "Epoch 95/300\n",
      "1/1 - 0s - loss: 1.5847 - accuracy: 0.6667 - 12ms/epoch - 12ms/step\n",
      "Epoch 96/300\n",
      "1/1 - 0s - loss: 1.5620 - accuracy: 0.6667 - 12ms/epoch - 12ms/step\n",
      "Epoch 97/300\n",
      "1/1 - 0s - loss: 1.5395 - accuracy: 0.6190 - 12ms/epoch - 12ms/step\n",
      "Epoch 98/300\n",
      "1/1 - 0s - loss: 1.5172 - accuracy: 0.6190 - 12ms/epoch - 12ms/step\n",
      "Epoch 99/300\n",
      "1/1 - 0s - loss: 1.4950 - accuracy: 0.6190 - 12ms/epoch - 12ms/step\n",
      "Epoch 100/300\n",
      "1/1 - 0s - loss: 1.4731 - accuracy: 0.6190 - 12ms/epoch - 12ms/step\n",
      "Epoch 101/300\n",
      "1/1 - 0s - loss: 1.4513 - accuracy: 0.6190 - 12ms/epoch - 12ms/step\n",
      "Epoch 102/300\n",
      "1/1 - 0s - loss: 1.4298 - accuracy: 0.6190 - 12ms/epoch - 12ms/step\n",
      "Epoch 103/300\n",
      "1/1 - 0s - loss: 1.4085 - accuracy: 0.6190 - 12ms/epoch - 12ms/step\n",
      "Epoch 104/300\n",
      "1/1 - 0s - loss: 1.3875 - accuracy: 0.6190 - 16ms/epoch - 16ms/step\n",
      "Epoch 105/300\n",
      "1/1 - 0s - loss: 1.3667 - accuracy: 0.6667 - 12ms/epoch - 12ms/step\n",
      "Epoch 106/300\n",
      "1/1 - 0s - loss: 1.3462 - accuracy: 0.7143 - 12ms/epoch - 12ms/step\n",
      "Epoch 107/300\n",
      "1/1 - 0s - loss: 1.3259 - accuracy: 0.7143 - 12ms/epoch - 12ms/step\n",
      "Epoch 108/300\n",
      "1/1 - 0s - loss: 1.3059 - accuracy: 0.7143 - 12ms/epoch - 12ms/step\n",
      "Epoch 109/300\n",
      "1/1 - 0s - loss: 1.2865 - accuracy: 0.7143 - 12ms/epoch - 12ms/step\n",
      "Epoch 110/300\n",
      "1/1 - 0s - loss: 1.2678 - accuracy: 0.7143 - 12ms/epoch - 12ms/step\n",
      "Epoch 111/300\n",
      "1/1 - 0s - loss: 1.2499 - accuracy: 0.7143 - 12ms/epoch - 12ms/step\n",
      "Epoch 112/300\n",
      "1/1 - 0s - loss: 1.2327 - accuracy: 0.7143 - 12ms/epoch - 12ms/step\n",
      "Epoch 113/300\n",
      "1/1 - 0s - loss: 1.2162 - accuracy: 0.7143 - 8ms/epoch - 8ms/step\n",
      "Epoch 114/300\n",
      "1/1 - 0s - loss: 1.2002 - accuracy: 0.7619 - 12ms/epoch - 12ms/step\n",
      "Epoch 115/300\n",
      "1/1 - 0s - loss: 1.1845 - accuracy: 0.7619 - 16ms/epoch - 16ms/step\n",
      "Epoch 116/300\n",
      "1/1 - 0s - loss: 1.1690 - accuracy: 0.7619 - 12ms/epoch - 12ms/step\n",
      "Epoch 117/300\n",
      "1/1 - 0s - loss: 1.1537 - accuracy: 0.7619 - 8ms/epoch - 8ms/step\n",
      "Epoch 118/300\n",
      "1/1 - 0s - loss: 1.1388 - accuracy: 0.7619 - 8ms/epoch - 8ms/step\n",
      "Epoch 119/300\n",
      "1/1 - 0s - loss: 1.1245 - accuracy: 0.7619 - 8ms/epoch - 8ms/step\n",
      "Epoch 120/300\n",
      "1/1 - 0s - loss: 1.1108 - accuracy: 0.7619 - 12ms/epoch - 12ms/step\n",
      "Epoch 121/300\n",
      "1/1 - 0s - loss: 1.0974 - accuracy: 0.7619 - 12ms/epoch - 12ms/step\n",
      "Epoch 122/300\n",
      "1/1 - 0s - loss: 1.0837 - accuracy: 0.7619 - 16ms/epoch - 16ms/step\n",
      "Epoch 123/300\n",
      "1/1 - 0s - loss: 1.0699 - accuracy: 0.7619 - 12ms/epoch - 12ms/step\n",
      "Epoch 124/300\n",
      "1/1 - 0s - loss: 1.0572 - accuracy: 0.7619 - 12ms/epoch - 12ms/step\n",
      "Epoch 125/300\n",
      "1/1 - 0s - loss: 1.0450 - accuracy: 0.7619 - 12ms/epoch - 12ms/step\n",
      "Epoch 126/300\n",
      "1/1 - 0s - loss: 1.0324 - accuracy: 0.7619 - 12ms/epoch - 12ms/step\n",
      "Epoch 127/300\n",
      "1/1 - 0s - loss: 1.0199 - accuracy: 0.7619 - 12ms/epoch - 12ms/step\n",
      "Epoch 128/300\n",
      "1/1 - 0s - loss: 1.0083 - accuracy: 0.7619 - 16ms/epoch - 16ms/step\n",
      "Epoch 129/300\n",
      "1/1 - 0s - loss: 0.9971 - accuracy: 0.7619 - 16ms/epoch - 16ms/step\n",
      "Epoch 130/300\n",
      "1/1 - 0s - loss: 0.9856 - accuracy: 0.7619 - 12ms/epoch - 12ms/step\n",
      "Epoch 131/300\n",
      "1/1 - 0s - loss: 0.9743 - accuracy: 0.7619 - 12ms/epoch - 12ms/step\n",
      "Epoch 132/300\n",
      "1/1 - 0s - loss: 0.9637 - accuracy: 0.7619 - 12ms/epoch - 12ms/step\n",
      "Epoch 133/300\n",
      "1/1 - 0s - loss: 0.9533 - accuracy: 0.7619 - 12ms/epoch - 12ms/step\n",
      "Epoch 134/300\n",
      "1/1 - 0s - loss: 0.9428 - accuracy: 0.7619 - 8ms/epoch - 8ms/step\n",
      "Epoch 135/300\n",
      "1/1 - 0s - loss: 0.9324 - accuracy: 0.7619 - 12ms/epoch - 12ms/step\n",
      "Epoch 136/300\n",
      "1/1 - 0s - loss: 0.9226 - accuracy: 0.7619 - 12ms/epoch - 12ms/step\n",
      "Epoch 137/300\n",
      "1/1 - 0s - loss: 0.9128 - accuracy: 0.7619 - 12ms/epoch - 12ms/step\n",
      "Epoch 138/300\n",
      "1/1 - 0s - loss: 0.9030 - accuracy: 0.7619 - 12ms/epoch - 12ms/step\n",
      "Epoch 139/300\n",
      "1/1 - 0s - loss: 0.8934 - accuracy: 0.7619 - 12ms/epoch - 12ms/step\n",
      "Epoch 140/300\n",
      "1/1 - 0s - loss: 0.8841 - accuracy: 0.8095 - 16ms/epoch - 16ms/step\n",
      "Epoch 141/300\n",
      "1/1 - 0s - loss: 0.8752 - accuracy: 0.7619 - 12ms/epoch - 12ms/step\n",
      "Epoch 142/300\n",
      "1/1 - 0s - loss: 0.8665 - accuracy: 0.8095 - 8ms/epoch - 8ms/step\n",
      "Epoch 143/300\n",
      "1/1 - 0s - loss: 0.8580 - accuracy: 0.8095 - 12ms/epoch - 12ms/step\n",
      "Epoch 144/300\n",
      "1/1 - 0s - loss: 0.8497 - accuracy: 0.8095 - 12ms/epoch - 12ms/step\n",
      "Epoch 145/300\n",
      "1/1 - 0s - loss: 0.8416 - accuracy: 0.8095 - 8ms/epoch - 8ms/step\n",
      "Epoch 146/300\n",
      "1/1 - 0s - loss: 0.8337 - accuracy: 0.8095 - 12ms/epoch - 12ms/step\n",
      "Epoch 147/300\n",
      "1/1 - 0s - loss: 0.8259 - accuracy: 0.8095 - 12ms/epoch - 12ms/step\n",
      "Epoch 148/300\n",
      "1/1 - 0s - loss: 0.8183 - accuracy: 0.8095 - 16ms/epoch - 16ms/step\n",
      "Epoch 149/300\n",
      "1/1 - 0s - loss: 0.8108 - accuracy: 0.8095 - 12ms/epoch - 12ms/step\n",
      "Epoch 150/300\n",
      "1/1 - 0s - loss: 0.8035 - accuracy: 0.8095 - 12ms/epoch - 12ms/step\n",
      "Epoch 151/300\n",
      "1/1 - 0s - loss: 0.7964 - accuracy: 0.8095 - 20ms/epoch - 20ms/step\n",
      "Epoch 152/300\n",
      "1/1 - 0s - loss: 0.7894 - accuracy: 0.8095 - 20ms/epoch - 20ms/step\n",
      "Epoch 153/300\n",
      "1/1 - 0s - loss: 0.7824 - accuracy: 0.8095 - 20ms/epoch - 20ms/step\n",
      "Epoch 154/300\n",
      "1/1 - 0s - loss: 0.7756 - accuracy: 0.8095 - 20ms/epoch - 20ms/step\n",
      "Epoch 155/300\n",
      "1/1 - 0s - loss: 0.7688 - accuracy: 0.8571 - 20ms/epoch - 20ms/step\n",
      "Epoch 156/300\n",
      "1/1 - 0s - loss: 0.7621 - accuracy: 0.8571 - 20ms/epoch - 20ms/step\n",
      "Epoch 157/300\n",
      "1/1 - 0s - loss: 0.7555 - accuracy: 0.8571 - 16ms/epoch - 16ms/step\n",
      "Epoch 158/300\n",
      "1/1 - 0s - loss: 0.7491 - accuracy: 0.8571 - 16ms/epoch - 16ms/step\n",
      "Epoch 159/300\n",
      "1/1 - 0s - loss: 0.7427 - accuracy: 0.8571 - 16ms/epoch - 16ms/step\n",
      "Epoch 160/300\n",
      "1/1 - 0s - loss: 0.7364 - accuracy: 0.8571 - 24ms/epoch - 24ms/step\n",
      "Epoch 161/300\n",
      "1/1 - 0s - loss: 0.7301 - accuracy: 0.8571 - 20ms/epoch - 20ms/step\n",
      "Epoch 162/300\n",
      "1/1 - 0s - loss: 0.7240 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 163/300\n",
      "1/1 - 0s - loss: 0.7179 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 164/300\n",
      "1/1 - 0s - loss: 0.7119 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 165/300\n",
      "1/1 - 0s - loss: 0.7061 - accuracy: 0.8571 - 8ms/epoch - 8ms/step\n",
      "Epoch 166/300\n",
      "1/1 - 0s - loss: 0.7006 - accuracy: 0.8571 - 8ms/epoch - 8ms/step\n",
      "Epoch 167/300\n",
      "1/1 - 0s - loss: 0.6953 - accuracy: 0.8571 - 8ms/epoch - 8ms/step\n",
      "Epoch 168/300\n",
      "1/1 - 0s - loss: 0.6898 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 169/300\n",
      "1/1 - 0s - loss: 0.6834 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 170/300\n",
      "1/1 - 0s - loss: 0.6769 - accuracy: 0.8571 - 16ms/epoch - 16ms/step\n",
      "Epoch 171/300\n",
      "1/1 - 0s - loss: 0.6716 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 172/300\n",
      "1/1 - 0s - loss: 0.6668 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 173/300\n",
      "1/1 - 0s - loss: 0.6613 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 174/300\n",
      "1/1 - 0s - loss: 0.6554 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 175/300\n",
      "1/1 - 0s - loss: 0.6502 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 176/300\n",
      "1/1 - 0s - loss: 0.6455 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 177/300\n",
      "1/1 - 0s - loss: 0.6402 - accuracy: 0.8571 - 20ms/epoch - 20ms/step\n",
      "Epoch 178/300\n",
      "1/1 - 0s - loss: 0.6348 - accuracy: 0.8571 - 16ms/epoch - 16ms/step\n",
      "Epoch 179/300\n",
      "1/1 - 0s - loss: 0.6299 - accuracy: 0.8571 - 16ms/epoch - 16ms/step\n",
      "Epoch 180/300\n",
      "1/1 - 0s - loss: 0.6253 - accuracy: 0.8571 - 20ms/epoch - 20ms/step\n",
      "Epoch 181/300\n",
      "1/1 - 0s - loss: 0.6203 - accuracy: 0.8571 - 20ms/epoch - 20ms/step\n",
      "Epoch 182/300\n",
      "1/1 - 0s - loss: 0.6152 - accuracy: 0.8571 - 20ms/epoch - 20ms/step\n",
      "Epoch 183/300\n",
      "1/1 - 0s - loss: 0.6105 - accuracy: 0.8571 - 16ms/epoch - 16ms/step\n",
      "Epoch 184/300\n",
      "1/1 - 0s - loss: 0.6060 - accuracy: 0.8571 - 20ms/epoch - 20ms/step\n",
      "Epoch 185/300\n",
      "1/1 - 0s - loss: 0.6012 - accuracy: 0.8571 - 16ms/epoch - 16ms/step\n",
      "Epoch 186/300\n",
      "1/1 - 0s - loss: 0.5964 - accuracy: 0.8571 - 16ms/epoch - 16ms/step\n",
      "Epoch 187/300\n",
      "1/1 - 0s - loss: 0.5919 - accuracy: 0.8571 - 23ms/epoch - 23ms/step\n",
      "Epoch 188/300\n",
      "1/1 - 0s - loss: 0.5875 - accuracy: 0.8571 - 15ms/epoch - 15ms/step\n",
      "Epoch 189/300\n",
      "1/1 - 0s - loss: 0.5829 - accuracy: 0.8571 - 20ms/epoch - 20ms/step\n",
      "Epoch 190/300\n",
      "1/1 - 0s - loss: 0.5783 - accuracy: 0.8571 - 16ms/epoch - 16ms/step\n",
      "Epoch 191/300\n",
      "1/1 - 0s - loss: 0.5740 - accuracy: 0.8571 - 16ms/epoch - 16ms/step\n",
      "Epoch 192/300\n",
      "1/1 - 0s - loss: 0.5698 - accuracy: 0.8571 - 20ms/epoch - 20ms/step\n",
      "Epoch 193/300\n",
      "1/1 - 0s - loss: 0.5654 - accuracy: 0.8571 - 16ms/epoch - 16ms/step\n",
      "Epoch 194/300\n",
      "1/1 - 0s - loss: 0.5611 - accuracy: 0.8571 - 16ms/epoch - 16ms/step\n",
      "Epoch 195/300\n",
      "1/1 - 0s - loss: 0.5568 - accuracy: 0.8571 - 16ms/epoch - 16ms/step\n",
      "Epoch 196/300\n",
      "1/1 - 0s - loss: 0.5527 - accuracy: 0.8571 - 16ms/epoch - 16ms/step\n",
      "Epoch 197/300\n",
      "1/1 - 0s - loss: 0.5487 - accuracy: 0.8571 - 20ms/epoch - 20ms/step\n",
      "Epoch 198/300\n",
      "1/1 - 0s - loss: 0.5445 - accuracy: 0.8571 - 17ms/epoch - 17ms/step\n",
      "Epoch 199/300\n",
      "1/1 - 0s - loss: 0.5405 - accuracy: 0.8571 - 16ms/epoch - 16ms/step\n",
      "Epoch 200/300\n",
      "1/1 - 0s - loss: 0.5365 - accuracy: 0.8571 - 20ms/epoch - 20ms/step\n",
      "Epoch 201/300\n",
      "1/1 - 0s - loss: 0.5325 - accuracy: 0.8571 - 16ms/epoch - 16ms/step\n",
      "Epoch 202/300\n",
      "1/1 - 0s - loss: 0.5287 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 203/300\n",
      "1/1 - 0s - loss: 0.5248 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 204/300\n",
      "1/1 - 0s - loss: 0.5209 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 205/300\n",
      "1/1 - 0s - loss: 0.5171 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 206/300\n",
      "1/1 - 0s - loss: 0.5134 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 207/300\n",
      "1/1 - 0s - loss: 0.5097 - accuracy: 0.8571 - 16ms/epoch - 16ms/step\n",
      "Epoch 208/300\n",
      "1/1 - 0s - loss: 0.5060 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 209/300\n",
      "1/1 - 0s - loss: 0.5024 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 210/300\n",
      "1/1 - 0s - loss: 0.4988 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 211/300\n",
      "1/1 - 0s - loss: 0.4952 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 212/300\n",
      "1/1 - 0s - loss: 0.4917 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 213/300\n",
      "1/1 - 0s - loss: 0.4882 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 214/300\n",
      "1/1 - 0s - loss: 0.4847 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 215/300\n",
      "1/1 - 0s - loss: 0.4813 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 216/300\n",
      "1/1 - 0s - loss: 0.4779 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 217/300\n",
      "1/1 - 0s - loss: 0.4746 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 218/300\n",
      "1/1 - 0s - loss: 0.4713 - accuracy: 0.8571 - 8ms/epoch - 8ms/step\n",
      "Epoch 219/300\n",
      "1/1 - 0s - loss: 0.4680 - accuracy: 0.8571 - 12ms/epoch - 12ms/step\n",
      "Epoch 220/300\n",
      "1/1 - 0s - loss: 0.4647 - accuracy: 0.9048 - 12ms/epoch - 12ms/step\n",
      "Epoch 221/300\n",
      "1/1 - 0s - loss: 0.4615 - accuracy: 0.9048 - 12ms/epoch - 12ms/step\n",
      "Epoch 222/300\n",
      "1/1 - 0s - loss: 0.4583 - accuracy: 0.9048 - 12ms/epoch - 12ms/step\n",
      "Epoch 223/300\n",
      "1/1 - 0s - loss: 0.4552 - accuracy: 0.9048 - 12ms/epoch - 12ms/step\n",
      "Epoch 224/300\n",
      "1/1 - 0s - loss: 0.4520 - accuracy: 0.9048 - 12ms/epoch - 12ms/step\n",
      "Epoch 225/300\n",
      "1/1 - 0s - loss: 0.4489 - accuracy: 0.9048 - 12ms/epoch - 12ms/step\n",
      "Epoch 226/300\n",
      "1/1 - 0s - loss: 0.4459 - accuracy: 0.9048 - 12ms/epoch - 12ms/step\n",
      "Epoch 227/300\n",
      "1/1 - 0s - loss: 0.4428 - accuracy: 0.9048 - 16ms/epoch - 16ms/step\n",
      "Epoch 228/300\n",
      "1/1 - 0s - loss: 0.4398 - accuracy: 0.9048 - 16ms/epoch - 16ms/step\n",
      "Epoch 229/300\n",
      "1/1 - 0s - loss: 0.4368 - accuracy: 0.9048 - 8ms/epoch - 8ms/step\n",
      "Epoch 230/300\n",
      "1/1 - 0s - loss: 0.4339 - accuracy: 0.9048 - 12ms/epoch - 12ms/step\n",
      "Epoch 231/300\n",
      "1/1 - 0s - loss: 0.4309 - accuracy: 0.9048 - 12ms/epoch - 12ms/step\n",
      "Epoch 232/300\n",
      "1/1 - 0s - loss: 0.4280 - accuracy: 0.9048 - 16ms/epoch - 16ms/step\n",
      "Epoch 233/300\n",
      "1/1 - 0s - loss: 0.4252 - accuracy: 0.9048 - 16ms/epoch - 16ms/step\n",
      "Epoch 234/300\n",
      "1/1 - 0s - loss: 0.4223 - accuracy: 0.9048 - 12ms/epoch - 12ms/step\n",
      "Epoch 235/300\n",
      "1/1 - 0s - loss: 0.4195 - accuracy: 0.9048 - 16ms/epoch - 16ms/step\n",
      "Epoch 236/300\n",
      "1/1 - 0s - loss: 0.4167 - accuracy: 0.9048 - 12ms/epoch - 12ms/step\n",
      "Epoch 237/300\n",
      "1/1 - 0s - loss: 0.4140 - accuracy: 0.9048 - 12ms/epoch - 12ms/step\n",
      "Epoch 238/300\n",
      "1/1 - 0s - loss: 0.4113 - accuracy: 0.9048 - 12ms/epoch - 12ms/step\n",
      "Epoch 239/300\n",
      "1/1 - 0s - loss: 0.4086 - accuracy: 0.9048 - 12ms/epoch - 12ms/step\n",
      "Epoch 240/300\n",
      "1/1 - 0s - loss: 0.4059 - accuracy: 0.9048 - 12ms/epoch - 12ms/step\n",
      "Epoch 241/300\n",
      "1/1 - 0s - loss: 0.4032 - accuracy: 0.9048 - 12ms/epoch - 12ms/step\n",
      "Epoch 242/300\n",
      "1/1 - 0s - loss: 0.4005 - accuracy: 0.9048 - 12ms/epoch - 12ms/step\n",
      "Epoch 243/300\n",
      "1/1 - 0s - loss: 0.3979 - accuracy: 0.9048 - 16ms/epoch - 16ms/step\n",
      "Epoch 244/300\n",
      "1/1 - 0s - loss: 0.3952 - accuracy: 0.9048 - 12ms/epoch - 12ms/step\n",
      "Epoch 245/300\n",
      "1/1 - 0s - loss: 0.3925 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 246/300\n",
      "1/1 - 0s - loss: 0.3899 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 247/300\n",
      "1/1 - 0s - loss: 0.3873 - accuracy: 0.9524 - 16ms/epoch - 16ms/step\n",
      "Epoch 248/300\n",
      "1/1 - 0s - loss: 0.3848 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 249/300\n",
      "1/1 - 0s - loss: 0.3823 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 250/300\n",
      "1/1 - 0s - loss: 0.3799 - accuracy: 0.9524 - 16ms/epoch - 16ms/step\n",
      "Epoch 251/300\n",
      "1/1 - 0s - loss: 0.3774 - accuracy: 0.9524 - 16ms/epoch - 16ms/step\n",
      "Epoch 252/300\n",
      "1/1 - 0s - loss: 0.3749 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 253/300\n",
      "1/1 - 0s - loss: 0.3725 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 254/300\n",
      "1/1 - 0s - loss: 0.3700 - accuracy: 0.9524 - 16ms/epoch - 16ms/step\n",
      "Epoch 255/300\n",
      "1/1 - 0s - loss: 0.3676 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 256/300\n",
      "1/1 - 0s - loss: 0.3651 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 257/300\n",
      "1/1 - 0s - loss: 0.3628 - accuracy: 0.9524 - 8ms/epoch - 8ms/step\n",
      "Epoch 258/300\n",
      "1/1 - 0s - loss: 0.3604 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 259/300\n",
      "1/1 - 0s - loss: 0.3581 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 260/300\n",
      "1/1 - 0s - loss: 0.3558 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 261/300\n",
      "1/1 - 0s - loss: 0.3535 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 262/300\n",
      "1/1 - 0s - loss: 0.3512 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 263/300\n",
      "1/1 - 0s - loss: 0.3489 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 264/300\n",
      "1/1 - 0s - loss: 0.3467 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 265/300\n",
      "1/1 - 0s - loss: 0.3444 - accuracy: 0.9524 - 8ms/epoch - 8ms/step\n",
      "Epoch 266/300\n",
      "1/1 - 0s - loss: 0.3422 - accuracy: 0.9524 - 16ms/epoch - 16ms/step\n",
      "Epoch 267/300\n",
      "1/1 - 0s - loss: 0.3399 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 268/300\n",
      "1/1 - 0s - loss: 0.3377 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 269/300\n",
      "1/1 - 0s - loss: 0.3355 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 270/300\n",
      "1/1 - 0s - loss: 0.3333 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 271/300\n",
      "1/1 - 0s - loss: 0.3312 - accuracy: 0.9524 - 16ms/epoch - 16ms/step\n",
      "Epoch 272/300\n",
      "1/1 - 0s - loss: 0.3290 - accuracy: 0.9524 - 16ms/epoch - 16ms/step\n",
      "Epoch 273/300\n",
      "1/1 - 0s - loss: 0.3269 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 274/300\n",
      "1/1 - 0s - loss: 0.3248 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 275/300\n",
      "1/1 - 0s - loss: 0.3227 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 276/300\n",
      "1/1 - 0s - loss: 0.3206 - accuracy: 0.9524 - 16ms/epoch - 16ms/step\n",
      "Epoch 277/300\n",
      "1/1 - 0s - loss: 0.3185 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 278/300\n",
      "1/1 - 0s - loss: 0.3164 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 279/300\n",
      "1/1 - 0s - loss: 0.3144 - accuracy: 0.9524 - 8ms/epoch - 8ms/step\n",
      "Epoch 280/300\n",
      "1/1 - 0s - loss: 0.3124 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 281/300\n",
      "1/1 - 0s - loss: 0.3103 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 282/300\n",
      "1/1 - 0s - loss: 0.3084 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 283/300\n",
      "1/1 - 0s - loss: 0.3064 - accuracy: 0.9524 - 8ms/epoch - 8ms/step\n",
      "Epoch 284/300\n",
      "1/1 - 0s - loss: 0.3045 - accuracy: 0.9524 - 8ms/epoch - 8ms/step\n",
      "Epoch 285/300\n",
      "1/1 - 0s - loss: 0.3025 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 286/300\n",
      "1/1 - 0s - loss: 0.3007 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 287/300\n",
      "1/1 - 0s - loss: 0.2988 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 288/300\n",
      "1/1 - 0s - loss: 0.2968 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 289/300\n",
      "1/1 - 0s - loss: 0.2949 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 290/300\n",
      "1/1 - 0s - loss: 0.2928 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 291/300\n",
      "1/1 - 0s - loss: 0.2908 - accuracy: 0.9524 - 16ms/epoch - 16ms/step\n",
      "Epoch 292/300\n",
      "1/1 - 0s - loss: 0.2888 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 293/300\n",
      "1/1 - 0s - loss: 0.2870 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 294/300\n",
      "1/1 - 0s - loss: 0.2852 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 295/300\n",
      "1/1 - 0s - loss: 0.2834 - accuracy: 0.9524 - 8ms/epoch - 8ms/step\n",
      "Epoch 296/300\n",
      "1/1 - 0s - loss: 0.2816 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 297/300\n",
      "1/1 - 0s - loss: 0.2797 - accuracy: 0.9524 - 8ms/epoch - 8ms/step\n",
      "Epoch 298/300\n",
      "1/1 - 0s - loss: 0.2779 - accuracy: 0.9524 - 16ms/epoch - 16ms/step\n",
      "Epoch 299/300\n",
      "1/1 - 0s - loss: 0.2760 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n",
      "Epoch 300/300\n",
      "1/1 - 0s - loss: 0.2742 - accuracy: 0.9524 - 12ms/epoch - 12ms/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=max_len-1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X, y, epochs=300, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c1c8426fd0>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_seq(model, tokenizer, max_len, seed_text, n_words):\n",
    "\n",
    "    for _ in range(n_words):\n",
    "\n",
    "        seq = array(tokenizer.texts_to_sequences([seed_text])[0])\n",
    "        seq = pad_sequences([seq], maxlen=max_len-1, padding='pre')\n",
    "\n",
    "        yhat = model.predict_on_batch([seq])\n",
    "\n",
    "        seed_text += ' ' + tokenizer.index_word[np.argmax(yhat)]\n",
    "\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Jack and Jill went up the hill\n",
      "\n",
      " To fetch a pail of water\n",
      "\n",
      " Jack fell down and broke his crown\n",
      "\n",
      " and Jill came tumbling after\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the fetch a\n"
     ]
    }
   ],
   "source": [
    "in_text = random.choice(list(tokenizer.word_index.keys()))\n",
    "\n",
    "print(gen_seq(model, tokenizer, max_len, in_text, 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Two-Words-In, One-Word-Out Sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_seq_prev_words(text, n_pervw=1):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts([text])\n",
    "    encoded = tokenizer.texts_to_sequences([text])[0]\n",
    "\n",
    "    sequences = array([encoded[i-n_pervw: i+1]\n",
    "                      for i in range(n_pervw, len(encoded))])\n",
    "\n",
    "    return sequences[:, :-1], to_categorical(sequences[:, -1], num_classes=len(tokenizer.word_index)+1), tokenizer, n_pervw+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, tok, maxlen = make_train_seq_prev_words(data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(X, y, max_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 10, input_length=max_len-1))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    print(model.summary())\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "    history = model.fit(X, y, epochs=300, verbose=2).history\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 2, 10)             220       \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 50)                12200     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 22)                1122      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13542 (52.90 KB)\n",
      "Trainable params: 13542 (52.90 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "1/1 - 2s - loss: 3.0907 - accuracy: 0.0435 - 2s/epoch - 2s/step\n",
      "Epoch 2/300\n",
      "1/1 - 0s - loss: 3.0898 - accuracy: 0.0000e+00 - 5ms/epoch - 5ms/step\n",
      "Epoch 3/300\n",
      "1/1 - 0s - loss: 3.0888 - accuracy: 0.0870 - 3ms/epoch - 3ms/step\n",
      "Epoch 4/300\n",
      "1/1 - 0s - loss: 3.0879 - accuracy: 0.0870 - 3ms/epoch - 3ms/step\n",
      "Epoch 5/300\n",
      "1/1 - 0s - loss: 3.0870 - accuracy: 0.0870 - 3ms/epoch - 3ms/step\n",
      "Epoch 6/300\n",
      "1/1 - 0s - loss: 3.0860 - accuracy: 0.0870 - 3ms/epoch - 3ms/step\n",
      "Epoch 7/300\n",
      "1/1 - 0s - loss: 3.0851 - accuracy: 0.0870 - 4ms/epoch - 4ms/step\n",
      "Epoch 8/300\n",
      "1/1 - 0s - loss: 3.0841 - accuracy: 0.0870 - 3ms/epoch - 3ms/step\n",
      "Epoch 9/300\n",
      "1/1 - 0s - loss: 3.0831 - accuracy: 0.1304 - 4ms/epoch - 4ms/step\n",
      "Epoch 10/300\n",
      "1/1 - 0s - loss: 3.0822 - accuracy: 0.1304 - 4ms/epoch - 4ms/step\n",
      "Epoch 11/300\n",
      "1/1 - 0s - loss: 3.0811 - accuracy: 0.1304 - 4ms/epoch - 4ms/step\n",
      "Epoch 12/300\n",
      "1/1 - 0s - loss: 3.0801 - accuracy: 0.1304 - 4ms/epoch - 4ms/step\n",
      "Epoch 13/300\n",
      "1/1 - 0s - loss: 3.0791 - accuracy: 0.1304 - 4ms/epoch - 4ms/step\n",
      "Epoch 14/300\n",
      "1/1 - 0s - loss: 3.0780 - accuracy: 0.1304 - 4ms/epoch - 4ms/step\n",
      "Epoch 15/300\n",
      "1/1 - 0s - loss: 3.0769 - accuracy: 0.1304 - 4ms/epoch - 4ms/step\n",
      "Epoch 16/300\n",
      "1/1 - 0s - loss: 3.0757 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 17/300\n",
      "1/1 - 0s - loss: 3.0746 - accuracy: 0.1739 - 3ms/epoch - 3ms/step\n",
      "Epoch 18/300\n",
      "1/1 - 0s - loss: 3.0734 - accuracy: 0.1739 - 3ms/epoch - 3ms/step\n",
      "Epoch 19/300\n",
      "1/1 - 0s - loss: 3.0721 - accuracy: 0.1739 - 3ms/epoch - 3ms/step\n",
      "Epoch 20/300\n",
      "1/1 - 0s - loss: 3.0708 - accuracy: 0.1739 - 3ms/epoch - 3ms/step\n",
      "Epoch 21/300\n",
      "1/1 - 0s - loss: 3.0695 - accuracy: 0.1739 - 3ms/epoch - 3ms/step\n",
      "Epoch 22/300\n",
      "1/1 - 0s - loss: 3.0682 - accuracy: 0.1739 - 3ms/epoch - 3ms/step\n",
      "Epoch 23/300\n",
      "1/1 - 0s - loss: 3.0668 - accuracy: 0.1739 - 3ms/epoch - 3ms/step\n",
      "Epoch 24/300\n",
      "1/1 - 0s - loss: 3.0653 - accuracy: 0.1739 - 3ms/epoch - 3ms/step\n",
      "Epoch 25/300\n",
      "1/1 - 0s - loss: 3.0638 - accuracy: 0.1739 - 3ms/epoch - 3ms/step\n",
      "Epoch 26/300\n",
      "1/1 - 0s - loss: 3.0622 - accuracy: 0.1739 - 3ms/epoch - 3ms/step\n",
      "Epoch 27/300\n",
      "1/1 - 0s - loss: 3.0606 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 28/300\n",
      "1/1 - 0s - loss: 3.0589 - accuracy: 0.1739 - 5ms/epoch - 5ms/step\n",
      "Epoch 29/300\n",
      "1/1 - 0s - loss: 3.0572 - accuracy: 0.1739 - 5ms/epoch - 5ms/step\n",
      "Epoch 30/300\n",
      "1/1 - 0s - loss: 3.0554 - accuracy: 0.1739 - 7ms/epoch - 7ms/step\n",
      "Epoch 31/300\n",
      "1/1 - 0s - loss: 3.0535 - accuracy: 0.1739 - 6ms/epoch - 6ms/step\n",
      "Epoch 32/300\n",
      "1/1 - 0s - loss: 3.0515 - accuracy: 0.1739 - 6ms/epoch - 6ms/step\n",
      "Epoch 33/300\n",
      "1/1 - 0s - loss: 3.0495 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 34/300\n",
      "1/1 - 0s - loss: 3.0474 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 35/300\n",
      "1/1 - 0s - loss: 3.0452 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 36/300\n",
      "1/1 - 0s - loss: 3.0429 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 37/300\n",
      "1/1 - 0s - loss: 3.0406 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 38/300\n",
      "1/1 - 0s - loss: 3.0381 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 39/300\n",
      "1/1 - 0s - loss: 3.0355 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 40/300\n",
      "1/1 - 0s - loss: 3.0329 - accuracy: 0.1739 - 3ms/epoch - 3ms/step\n",
      "Epoch 41/300\n",
      "1/1 - 0s - loss: 3.0301 - accuracy: 0.1739 - 3ms/epoch - 3ms/step\n",
      "Epoch 42/300\n",
      "1/1 - 0s - loss: 3.0272 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 43/300\n",
      "1/1 - 0s - loss: 3.0241 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 44/300\n",
      "1/1 - 0s - loss: 3.0210 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 45/300\n",
      "1/1 - 0s - loss: 3.0177 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 46/300\n",
      "1/1 - 0s - loss: 3.0143 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 47/300\n",
      "1/1 - 0s - loss: 3.0107 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 48/300\n",
      "1/1 - 0s - loss: 3.0070 - accuracy: 0.1739 - 5ms/epoch - 5ms/step\n",
      "Epoch 49/300\n",
      "1/1 - 0s - loss: 3.0032 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 50/300\n",
      "1/1 - 0s - loss: 2.9992 - accuracy: 0.1739 - 5ms/epoch - 5ms/step\n",
      "Epoch 51/300\n",
      "1/1 - 0s - loss: 2.9950 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 52/300\n",
      "1/1 - 0s - loss: 2.9906 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 53/300\n",
      "1/1 - 0s - loss: 2.9860 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 54/300\n",
      "1/1 - 0s - loss: 2.9813 - accuracy: 0.1739 - 3ms/epoch - 3ms/step\n",
      "Epoch 55/300\n",
      "1/1 - 0s - loss: 2.9763 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 56/300\n",
      "1/1 - 0s - loss: 2.9712 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 57/300\n",
      "1/1 - 0s - loss: 2.9658 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 58/300\n",
      "1/1 - 0s - loss: 2.9602 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 59/300\n",
      "1/1 - 0s - loss: 2.9544 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 60/300\n",
      "1/1 - 0s - loss: 2.9483 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 61/300\n",
      "1/1 - 0s - loss: 2.9420 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 62/300\n",
      "1/1 - 0s - loss: 2.9354 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 63/300\n",
      "1/1 - 0s - loss: 2.9286 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 64/300\n",
      "1/1 - 0s - loss: 2.9215 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 65/300\n",
      "1/1 - 0s - loss: 2.9140 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 66/300\n",
      "1/1 - 0s - loss: 2.9063 - accuracy: 0.1739 - 3ms/epoch - 3ms/step\n",
      "Epoch 67/300\n",
      "1/1 - 0s - loss: 2.8983 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 68/300\n",
      "1/1 - 0s - loss: 2.8899 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 69/300\n",
      "1/1 - 0s - loss: 2.8812 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 70/300\n",
      "1/1 - 0s - loss: 2.8722 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 71/300\n",
      "1/1 - 0s - loss: 2.8628 - accuracy: 0.1739 - 3ms/epoch - 3ms/step\n",
      "Epoch 72/300\n",
      "1/1 - 0s - loss: 2.8531 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 73/300\n",
      "1/1 - 0s - loss: 2.8430 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 74/300\n",
      "1/1 - 0s - loss: 2.8325 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 75/300\n",
      "1/1 - 0s - loss: 2.8216 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 76/300\n",
      "1/1 - 0s - loss: 2.8103 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 77/300\n",
      "1/1 - 0s - loss: 2.7986 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 78/300\n",
      "1/1 - 0s - loss: 2.7864 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 79/300\n",
      "1/1 - 0s - loss: 2.7738 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 80/300\n",
      "1/1 - 0s - loss: 2.7608 - accuracy: 0.1739 - 6ms/epoch - 6ms/step\n",
      "Epoch 81/300\n",
      "1/1 - 0s - loss: 2.7474 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 82/300\n",
      "1/1 - 0s - loss: 2.7334 - accuracy: 0.1739 - 5ms/epoch - 5ms/step\n",
      "Epoch 83/300\n",
      "1/1 - 0s - loss: 2.7190 - accuracy: 0.1739 - 4ms/epoch - 4ms/step\n",
      "Epoch 84/300\n",
      "1/1 - 0s - loss: 2.7042 - accuracy: 0.1739 - 5ms/epoch - 5ms/step\n",
      "Epoch 85/300\n",
      "1/1 - 0s - loss: 2.6889 - accuracy: 0.2174 - 5ms/epoch - 5ms/step\n",
      "Epoch 86/300\n",
      "1/1 - 0s - loss: 2.6730 - accuracy: 0.2174 - 4ms/epoch - 4ms/step\n",
      "Epoch 87/300\n",
      "1/1 - 0s - loss: 2.6568 - accuracy: 0.2174 - 4ms/epoch - 4ms/step\n",
      "Epoch 88/300\n",
      "1/1 - 0s - loss: 2.6400 - accuracy: 0.2174 - 3ms/epoch - 3ms/step\n",
      "Epoch 89/300\n",
      "1/1 - 0s - loss: 2.6227 - accuracy: 0.2609 - 4ms/epoch - 4ms/step\n",
      "Epoch 90/300\n",
      "1/1 - 0s - loss: 2.6050 - accuracy: 0.2609 - 3ms/epoch - 3ms/step\n",
      "Epoch 91/300\n",
      "1/1 - 0s - loss: 2.5868 - accuracy: 0.2609 - 4ms/epoch - 4ms/step\n",
      "Epoch 92/300\n",
      "1/1 - 0s - loss: 2.5681 - accuracy: 0.2609 - 4ms/epoch - 4ms/step\n",
      "Epoch 93/300\n",
      "1/1 - 0s - loss: 2.5490 - accuracy: 0.2609 - 3ms/epoch - 3ms/step\n",
      "Epoch 94/300\n",
      "1/1 - 0s - loss: 2.5294 - accuracy: 0.2609 - 3ms/epoch - 3ms/step\n",
      "Epoch 95/300\n",
      "1/1 - 0s - loss: 2.5094 - accuracy: 0.2609 - 3ms/epoch - 3ms/step\n",
      "Epoch 96/300\n",
      "1/1 - 0s - loss: 2.4889 - accuracy: 0.2609 - 3ms/epoch - 3ms/step\n",
      "Epoch 97/300\n",
      "1/1 - 0s - loss: 2.4680 - accuracy: 0.2609 - 4ms/epoch - 4ms/step\n",
      "Epoch 98/300\n",
      "1/1 - 0s - loss: 2.4468 - accuracy: 0.2609 - 3ms/epoch - 3ms/step\n",
      "Epoch 99/300\n",
      "1/1 - 0s - loss: 2.4251 - accuracy: 0.2609 - 3ms/epoch - 3ms/step\n",
      "Epoch 100/300\n",
      "1/1 - 0s - loss: 2.4031 - accuracy: 0.3478 - 3ms/epoch - 3ms/step\n",
      "Epoch 101/300\n",
      "1/1 - 0s - loss: 2.3807 - accuracy: 0.3478 - 3ms/epoch - 3ms/step\n",
      "Epoch 102/300\n",
      "1/1 - 0s - loss: 2.3581 - accuracy: 0.3478 - 3ms/epoch - 3ms/step\n",
      "Epoch 103/300\n",
      "1/1 - 0s - loss: 2.3351 - accuracy: 0.3478 - 3ms/epoch - 3ms/step\n",
      "Epoch 104/300\n",
      "1/1 - 0s - loss: 2.3119 - accuracy: 0.3478 - 4ms/epoch - 4ms/step\n",
      "Epoch 105/300\n",
      "1/1 - 0s - loss: 2.2884 - accuracy: 0.3478 - 3ms/epoch - 3ms/step\n",
      "Epoch 106/300\n",
      "1/1 - 0s - loss: 2.2647 - accuracy: 0.3478 - 3ms/epoch - 3ms/step\n",
      "Epoch 107/300\n",
      "1/1 - 0s - loss: 2.2409 - accuracy: 0.3913 - 3ms/epoch - 3ms/step\n",
      "Epoch 108/300\n",
      "1/1 - 0s - loss: 2.2169 - accuracy: 0.3913 - 4ms/epoch - 4ms/step\n",
      "Epoch 109/300\n",
      "1/1 - 0s - loss: 2.1927 - accuracy: 0.4348 - 3ms/epoch - 3ms/step\n",
      "Epoch 110/300\n",
      "1/1 - 0s - loss: 2.1685 - accuracy: 0.4348 - 3ms/epoch - 3ms/step\n",
      "Epoch 111/300\n",
      "1/1 - 0s - loss: 2.1441 - accuracy: 0.3913 - 3ms/epoch - 3ms/step\n",
      "Epoch 112/300\n",
      "1/1 - 0s - loss: 2.1198 - accuracy: 0.3913 - 3ms/epoch - 3ms/step\n",
      "Epoch 113/300\n",
      "1/1 - 0s - loss: 2.0954 - accuracy: 0.3913 - 3ms/epoch - 3ms/step\n",
      "Epoch 114/300\n",
      "1/1 - 0s - loss: 2.0710 - accuracy: 0.3913 - 4ms/epoch - 4ms/step\n",
      "Epoch 115/300\n",
      "1/1 - 0s - loss: 2.0466 - accuracy: 0.3913 - 4ms/epoch - 4ms/step\n",
      "Epoch 116/300\n",
      "1/1 - 0s - loss: 2.0223 - accuracy: 0.4348 - 4ms/epoch - 4ms/step\n",
      "Epoch 117/300\n",
      "1/1 - 0s - loss: 1.9980 - accuracy: 0.4348 - 4ms/epoch - 4ms/step\n",
      "Epoch 118/300\n",
      "1/1 - 0s - loss: 1.9737 - accuracy: 0.4348 - 4ms/epoch - 4ms/step\n",
      "Epoch 119/300\n",
      "1/1 - 0s - loss: 1.9496 - accuracy: 0.4783 - 3ms/epoch - 3ms/step\n",
      "Epoch 120/300\n",
      "1/1 - 0s - loss: 1.9255 - accuracy: 0.4783 - 4ms/epoch - 4ms/step\n",
      "Epoch 121/300\n",
      "1/1 - 0s - loss: 1.9016 - accuracy: 0.4783 - 3ms/epoch - 3ms/step\n",
      "Epoch 122/300\n",
      "1/1 - 0s - loss: 1.8777 - accuracy: 0.4783 - 3ms/epoch - 3ms/step\n",
      "Epoch 123/300\n",
      "1/1 - 0s - loss: 1.8540 - accuracy: 0.4783 - 4ms/epoch - 4ms/step\n",
      "Epoch 124/300\n",
      "1/1 - 0s - loss: 1.8303 - accuracy: 0.4783 - 3ms/epoch - 3ms/step\n",
      "Epoch 125/300\n",
      "1/1 - 0s - loss: 1.8068 - accuracy: 0.4783 - 4ms/epoch - 4ms/step\n",
      "Epoch 126/300\n",
      "1/1 - 0s - loss: 1.7834 - accuracy: 0.4783 - 5ms/epoch - 5ms/step\n",
      "Epoch 127/300\n",
      "1/1 - 0s - loss: 1.7601 - accuracy: 0.4783 - 5ms/epoch - 5ms/step\n",
      "Epoch 128/300\n",
      "1/1 - 0s - loss: 1.7369 - accuracy: 0.4783 - 8ms/epoch - 8ms/step\n",
      "Epoch 129/300\n",
      "1/1 - 0s - loss: 1.7138 - accuracy: 0.4783 - 6ms/epoch - 6ms/step\n",
      "Epoch 130/300\n",
      "1/1 - 0s - loss: 1.6909 - accuracy: 0.4783 - 4ms/epoch - 4ms/step\n",
      "Epoch 131/300\n",
      "1/1 - 0s - loss: 1.6680 - accuracy: 0.4783 - 6ms/epoch - 6ms/step\n",
      "Epoch 132/300\n",
      "1/1 - 0s - loss: 1.6453 - accuracy: 0.5217 - 4ms/epoch - 4ms/step\n",
      "Epoch 133/300\n",
      "1/1 - 0s - loss: 1.6226 - accuracy: 0.6087 - 4ms/epoch - 4ms/step\n",
      "Epoch 134/300\n",
      "1/1 - 0s - loss: 1.6001 - accuracy: 0.6087 - 4ms/epoch - 4ms/step\n",
      "Epoch 135/300\n",
      "1/1 - 0s - loss: 1.5776 - accuracy: 0.6087 - 3ms/epoch - 3ms/step\n",
      "Epoch 136/300\n",
      "1/1 - 0s - loss: 1.5553 - accuracy: 0.6087 - 3ms/epoch - 3ms/step\n",
      "Epoch 137/300\n",
      "1/1 - 0s - loss: 1.5330 - accuracy: 0.6522 - 3ms/epoch - 3ms/step\n",
      "Epoch 138/300\n",
      "1/1 - 0s - loss: 1.5109 - accuracy: 0.6522 - 4ms/epoch - 4ms/step\n",
      "Epoch 139/300\n",
      "1/1 - 0s - loss: 1.4888 - accuracy: 0.6957 - 3ms/epoch - 3ms/step\n",
      "Epoch 140/300\n",
      "1/1 - 0s - loss: 1.4669 - accuracy: 0.6957 - 3ms/epoch - 3ms/step\n",
      "Epoch 141/300\n",
      "1/1 - 0s - loss: 1.4450 - accuracy: 0.7826 - 4ms/epoch - 4ms/step\n",
      "Epoch 142/300\n",
      "1/1 - 0s - loss: 1.4233 - accuracy: 0.7826 - 3ms/epoch - 3ms/step\n",
      "Epoch 143/300\n",
      "1/1 - 0s - loss: 1.4016 - accuracy: 0.7826 - 3ms/epoch - 3ms/step\n",
      "Epoch 144/300\n",
      "1/1 - 0s - loss: 1.3800 - accuracy: 0.7826 - 4ms/epoch - 4ms/step\n",
      "Epoch 145/300\n",
      "1/1 - 0s - loss: 1.3586 - accuracy: 0.7826 - 4ms/epoch - 4ms/step\n",
      "Epoch 146/300\n",
      "1/1 - 0s - loss: 1.3372 - accuracy: 0.7826 - 4ms/epoch - 4ms/step\n",
      "Epoch 147/300\n",
      "1/1 - 0s - loss: 1.3159 - accuracy: 0.7826 - 4ms/epoch - 4ms/step\n",
      "Epoch 148/300\n",
      "1/1 - 0s - loss: 1.2947 - accuracy: 0.7826 - 5ms/epoch - 5ms/step\n",
      "Epoch 149/300\n",
      "1/1 - 0s - loss: 1.2736 - accuracy: 0.7826 - 5ms/epoch - 5ms/step\n",
      "Epoch 150/300\n",
      "1/1 - 0s - loss: 1.2526 - accuracy: 0.7826 - 4ms/epoch - 4ms/step\n",
      "Epoch 151/300\n",
      "1/1 - 0s - loss: 1.2316 - accuracy: 0.7826 - 4ms/epoch - 4ms/step\n",
      "Epoch 152/300\n",
      "1/1 - 0s - loss: 1.2108 - accuracy: 0.7826 - 4ms/epoch - 4ms/step\n",
      "Epoch 153/300\n",
      "1/1 - 0s - loss: 1.1900 - accuracy: 0.8261 - 4ms/epoch - 4ms/step\n",
      "Epoch 154/300\n",
      "1/1 - 0s - loss: 1.1694 - accuracy: 0.8261 - 4ms/epoch - 4ms/step\n",
      "Epoch 155/300\n",
      "1/1 - 0s - loss: 1.1488 - accuracy: 0.8261 - 4ms/epoch - 4ms/step\n",
      "Epoch 156/300\n",
      "1/1 - 0s - loss: 1.1283 - accuracy: 0.8261 - 5ms/epoch - 5ms/step\n",
      "Epoch 157/300\n",
      "1/1 - 0s - loss: 1.1079 - accuracy: 0.8261 - 4ms/epoch - 4ms/step\n",
      "Epoch 158/300\n",
      "1/1 - 0s - loss: 1.0876 - accuracy: 0.8261 - 4ms/epoch - 4ms/step\n",
      "Epoch 159/300\n",
      "1/1 - 0s - loss: 1.0674 - accuracy: 0.8696 - 5ms/epoch - 5ms/step\n",
      "Epoch 160/300\n",
      "1/1 - 0s - loss: 1.0473 - accuracy: 0.8696 - 4ms/epoch - 4ms/step\n",
      "Epoch 161/300\n",
      "1/1 - 0s - loss: 1.0274 - accuracy: 0.8696 - 4ms/epoch - 4ms/step\n",
      "Epoch 162/300\n",
      "1/1 - 0s - loss: 1.0075 - accuracy: 0.8696 - 4ms/epoch - 4ms/step\n",
      "Epoch 163/300\n",
      "1/1 - 0s - loss: 0.9878 - accuracy: 0.8696 - 4ms/epoch - 4ms/step\n",
      "Epoch 164/300\n",
      "1/1 - 0s - loss: 0.9682 - accuracy: 0.8696 - 4ms/epoch - 4ms/step\n",
      "Epoch 165/300\n",
      "1/1 - 0s - loss: 0.9487 - accuracy: 0.8696 - 4ms/epoch - 4ms/step\n",
      "Epoch 166/300\n",
      "1/1 - 0s - loss: 0.9294 - accuracy: 0.8696 - 3ms/epoch - 3ms/step\n",
      "Epoch 167/300\n",
      "1/1 - 0s - loss: 0.9103 - accuracy: 0.9130 - 3ms/epoch - 3ms/step\n",
      "Epoch 168/300\n",
      "1/1 - 0s - loss: 0.8913 - accuracy: 0.9130 - 3ms/epoch - 3ms/step\n",
      "Epoch 169/300\n",
      "1/1 - 0s - loss: 0.8725 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 170/300\n",
      "1/1 - 0s - loss: 0.8539 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 171/300\n",
      "1/1 - 0s - loss: 0.8355 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 172/300\n",
      "1/1 - 0s - loss: 0.8173 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 173/300\n",
      "1/1 - 0s - loss: 0.7993 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 174/300\n",
      "1/1 - 0s - loss: 0.7816 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 175/300\n",
      "1/1 - 0s - loss: 0.7641 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 176/300\n",
      "1/1 - 0s - loss: 0.7469 - accuracy: 0.9565 - 6ms/epoch - 6ms/step\n",
      "Epoch 177/300\n",
      "1/1 - 0s - loss: 0.7299 - accuracy: 0.9565 - 5ms/epoch - 5ms/step\n",
      "Epoch 178/300\n",
      "1/1 - 0s - loss: 0.7132 - accuracy: 0.9565 - 7ms/epoch - 7ms/step\n",
      "Epoch 179/300\n",
      "1/1 - 0s - loss: 0.6968 - accuracy: 0.9565 - 5ms/epoch - 5ms/step\n",
      "Epoch 180/300\n",
      "1/1 - 0s - loss: 0.6806 - accuracy: 0.9565 - 5ms/epoch - 5ms/step\n",
      "Epoch 181/300\n",
      "1/1 - 0s - loss: 0.6648 - accuracy: 0.9565 - 5ms/epoch - 5ms/step\n",
      "Epoch 182/300\n",
      "1/1 - 0s - loss: 0.6492 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 183/300\n",
      "1/1 - 0s - loss: 0.6340 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 184/300\n",
      "1/1 - 0s - loss: 0.6190 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 185/300\n",
      "1/1 - 0s - loss: 0.6044 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 186/300\n",
      "1/1 - 0s - loss: 0.5901 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 187/300\n",
      "1/1 - 0s - loss: 0.5761 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 188/300\n",
      "1/1 - 0s - loss: 0.5625 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 189/300\n",
      "1/1 - 0s - loss: 0.5491 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 190/300\n",
      "1/1 - 0s - loss: 0.5361 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 191/300\n",
      "1/1 - 0s - loss: 0.5235 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 192/300\n",
      "1/1 - 0s - loss: 0.5111 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 193/300\n",
      "1/1 - 0s - loss: 0.4991 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 194/300\n",
      "1/1 - 0s - loss: 0.4874 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 195/300\n",
      "1/1 - 0s - loss: 0.4760 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 196/300\n",
      "1/1 - 0s - loss: 0.4649 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 197/300\n",
      "1/1 - 0s - loss: 0.4542 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 198/300\n",
      "1/1 - 0s - loss: 0.4437 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 199/300\n",
      "1/1 - 0s - loss: 0.4336 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 200/300\n",
      "1/1 - 0s - loss: 0.4238 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 201/300\n",
      "1/1 - 0s - loss: 0.4143 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 202/300\n",
      "1/1 - 0s - loss: 0.4050 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 203/300\n",
      "1/1 - 0s - loss: 0.3961 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 204/300\n",
      "1/1 - 0s - loss: 0.3875 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 205/300\n",
      "1/1 - 0s - loss: 0.3791 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 206/300\n",
      "1/1 - 0s - loss: 0.3710 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 207/300\n",
      "1/1 - 0s - loss: 0.3631 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 208/300\n",
      "1/1 - 0s - loss: 0.3555 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 209/300\n",
      "1/1 - 0s - loss: 0.3482 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 210/300\n",
      "1/1 - 0s - loss: 0.3411 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 211/300\n",
      "1/1 - 0s - loss: 0.3342 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 212/300\n",
      "1/1 - 0s - loss: 0.3276 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 213/300\n",
      "1/1 - 0s - loss: 0.3212 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 214/300\n",
      "1/1 - 0s - loss: 0.3150 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 215/300\n",
      "1/1 - 0s - loss: 0.3090 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 216/300\n",
      "1/1 - 0s - loss: 0.3032 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 217/300\n",
      "1/1 - 0s - loss: 0.2976 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 218/300\n",
      "1/1 - 0s - loss: 0.2922 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 219/300\n",
      "1/1 - 0s - loss: 0.2870 - accuracy: 0.9565 - 5ms/epoch - 5ms/step\n",
      "Epoch 220/300\n",
      "1/1 - 0s - loss: 0.2819 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 221/300\n",
      "1/1 - 0s - loss: 0.2771 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 222/300\n",
      "1/1 - 0s - loss: 0.2724 - accuracy: 0.9565 - 5ms/epoch - 5ms/step\n",
      "Epoch 223/300\n",
      "1/1 - 0s - loss: 0.2678 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 224/300\n",
      "1/1 - 0s - loss: 0.2634 - accuracy: 0.9565 - 5ms/epoch - 5ms/step\n",
      "Epoch 225/300\n",
      "1/1 - 0s - loss: 0.2591 - accuracy: 0.9565 - 5ms/epoch - 5ms/step\n",
      "Epoch 226/300\n",
      "1/1 - 0s - loss: 0.2550 - accuracy: 0.9565 - 6ms/epoch - 6ms/step\n",
      "Epoch 227/300\n",
      "1/1 - 0s - loss: 0.2510 - accuracy: 0.9565 - 6ms/epoch - 6ms/step\n",
      "Epoch 228/300\n",
      "1/1 - 0s - loss: 0.2471 - accuracy: 0.9565 - 5ms/epoch - 5ms/step\n",
      "Epoch 229/300\n",
      "1/1 - 0s - loss: 0.2434 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 230/300\n",
      "1/1 - 0s - loss: 0.2397 - accuracy: 0.9565 - 5ms/epoch - 5ms/step\n",
      "Epoch 231/300\n",
      "1/1 - 0s - loss: 0.2362 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 232/300\n",
      "1/1 - 0s - loss: 0.2328 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 233/300\n",
      "1/1 - 0s - loss: 0.2295 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 234/300\n",
      "1/1 - 0s - loss: 0.2263 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 235/300\n",
      "1/1 - 0s - loss: 0.2232 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 236/300\n",
      "1/1 - 0s - loss: 0.2202 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 237/300\n",
      "1/1 - 0s - loss: 0.2172 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 238/300\n",
      "1/1 - 0s - loss: 0.2144 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 239/300\n",
      "1/1 - 0s - loss: 0.2116 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 240/300\n",
      "1/1 - 0s - loss: 0.2089 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 241/300\n",
      "1/1 - 0s - loss: 0.2063 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 242/300\n",
      "1/1 - 0s - loss: 0.2038 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 243/300\n",
      "1/1 - 0s - loss: 0.2013 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 244/300\n",
      "1/1 - 0s - loss: 0.1989 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 245/300\n",
      "1/1 - 0s - loss: 0.1965 - accuracy: 0.9565 - 5ms/epoch - 5ms/step\n",
      "Epoch 246/300\n",
      "1/1 - 0s - loss: 0.1942 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 247/300\n",
      "1/1 - 0s - loss: 0.1920 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 248/300\n",
      "1/1 - 0s - loss: 0.1898 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 249/300\n",
      "1/1 - 0s - loss: 0.1877 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 250/300\n",
      "1/1 - 0s - loss: 0.1856 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 251/300\n",
      "1/1 - 0s - loss: 0.1836 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 252/300\n",
      "1/1 - 0s - loss: 0.1816 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 253/300\n",
      "1/1 - 0s - loss: 0.1797 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 254/300\n",
      "1/1 - 0s - loss: 0.1778 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 255/300\n",
      "1/1 - 0s - loss: 0.1759 - accuracy: 0.9565 - 5ms/epoch - 5ms/step\n",
      "Epoch 256/300\n",
      "1/1 - 0s - loss: 0.1741 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 257/300\n",
      "1/1 - 0s - loss: 0.1723 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 258/300\n",
      "1/1 - 0s - loss: 0.1706 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 259/300\n",
      "1/1 - 0s - loss: 0.1689 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 260/300\n",
      "1/1 - 0s - loss: 0.1672 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 261/300\n",
      "1/1 - 0s - loss: 0.1656 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 262/300\n",
      "1/1 - 0s - loss: 0.1640 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 263/300\n",
      "1/1 - 0s - loss: 0.1624 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 264/300\n",
      "1/1 - 0s - loss: 0.1609 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 265/300\n",
      "1/1 - 0s - loss: 0.1594 - accuracy: 0.9565 - 6ms/epoch - 6ms/step\n",
      "Epoch 266/300\n",
      "1/1 - 0s - loss: 0.1579 - accuracy: 0.9565 - 5ms/epoch - 5ms/step\n",
      "Epoch 267/300\n",
      "1/1 - 0s - loss: 0.1564 - accuracy: 0.9565 - 8ms/epoch - 8ms/step\n",
      "Epoch 268/300\n",
      "1/1 - 0s - loss: 0.1550 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 269/300\n",
      "1/1 - 0s - loss: 0.1536 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 270/300\n",
      "1/1 - 0s - loss: 0.1522 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 271/300\n",
      "1/1 - 0s - loss: 0.1508 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 272/300\n",
      "1/1 - 0s - loss: 0.1495 - accuracy: 0.9565 - 5ms/epoch - 5ms/step\n",
      "Epoch 273/300\n",
      "1/1 - 0s - loss: 0.1482 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 274/300\n",
      "1/1 - 0s - loss: 0.1469 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 275/300\n",
      "1/1 - 0s - loss: 0.1456 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 276/300\n",
      "1/1 - 0s - loss: 0.1444 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 277/300\n",
      "1/1 - 0s - loss: 0.1432 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 278/300\n",
      "1/1 - 0s - loss: 0.1420 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 279/300\n",
      "1/1 - 0s - loss: 0.1408 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 280/300\n",
      "1/1 - 0s - loss: 0.1396 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 281/300\n",
      "1/1 - 0s - loss: 0.1385 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 282/300\n",
      "1/1 - 0s - loss: 0.1373 - accuracy: 0.9565 - 5ms/epoch - 5ms/step\n",
      "Epoch 283/300\n",
      "1/1 - 0s - loss: 0.1362 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 284/300\n",
      "1/1 - 0s - loss: 0.1351 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 285/300\n",
      "1/1 - 0s - loss: 0.1340 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 286/300\n",
      "1/1 - 0s - loss: 0.1330 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 287/300\n",
      "1/1 - 0s - loss: 0.1319 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 288/300\n",
      "1/1 - 0s - loss: 0.1309 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 289/300\n",
      "1/1 - 0s - loss: 0.1299 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 290/300\n",
      "1/1 - 0s - loss: 0.1289 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 291/300\n",
      "1/1 - 0s - loss: 0.1279 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 292/300\n",
      "1/1 - 0s - loss: 0.1270 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 293/300\n",
      "1/1 - 0s - loss: 0.1260 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 294/300\n",
      "1/1 - 0s - loss: 0.1251 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 295/300\n",
      "1/1 - 0s - loss: 0.1242 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 296/300\n",
      "1/1 - 0s - loss: 0.1233 - accuracy: 0.9565 - 5ms/epoch - 5ms/step\n",
      "Epoch 297/300\n",
      "1/1 - 0s - loss: 0.1224 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 298/300\n",
      "1/1 - 0s - loss: 0.1215 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n",
      "Epoch 299/300\n",
      "1/1 - 0s - loss: 0.1207 - accuracy: 0.9565 - 4ms/epoch - 4ms/step\n",
      "Epoch 300/300\n",
      "1/1 - 0s - loss: 0.1198 - accuracy: 0.9565 - 3ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model, history = make_model(X, y, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_top_next_word(model, tokenizer, max_len, seed_text, n_words):\n",
    "\n",
    "    seq = array(tokenizer.texts_to_sequences([seed_text])[0])\n",
    "    seq = pad_sequences([seq], maxlen=max_len-1, padding='pre')\n",
    "\n",
    "    yhat = model.predict_on_batch([seq])\n",
    "\n",
    "    out_text = [tokenizer.index_word[i]\n",
    "                for i in np.argsort(yhat)[0][::-1][:n_words]]\n",
    "\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Jack and Jill went up the hill\n",
      "\n",
      " To fetch a pail of water\n",
      "\n",
      " Jack fell down and broke his crown\n",
      "\n",
      " and Jill came tumbling after\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jill', 'down']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_top_next_word(model, tok, maxlen, 'Jack love', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jill went up the hill'"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_seq(model, tok, maxlen, 'Jill went', 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
